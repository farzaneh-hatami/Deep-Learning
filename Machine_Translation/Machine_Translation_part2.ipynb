{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_part2_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IOB4XiizglA",
        "outputId": "265f6f94-c40c-4623-ad12-15167fe657b2"
      },
      "source": [
        "pip install hazm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 7.6MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 52.4MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 18.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n",
            "Building wheels for collected packages: libwapiti, nltk\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154172 sha256=bda4717dafd932615c19342e164d1c7d6770185bc669f35b00a6ff438891e678\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394485 sha256=5f40048331dcd637f828d05d9933f60c3e0a419200e361fefc4de05cfeaa2e45\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built libwapiti nltk\n",
            "Installing collected packages: libwapiti, nltk, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZk20AR5_NtE",
        "outputId": "8b44786e-19bf-441d-894a-ad8527390710"
      },
      "source": [
        "! pip install -q pyonmttok"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.3MB 196kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH9TJe4XVCGh"
      },
      "source": [
        "# **Processing Data with torchtext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln1NpZEyjcHg"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch \n",
        "import requests\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "from hazm import *\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import pyonmttok\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXfx5UQGtS4",
        "outputId": "5dad6144-5098-4039-b627-c900e0186c19"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huEQHXpGjjfC",
        "outputId": "6d925ae6-554a-478b-c09d-d488f2602733"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMwBHXEs7lML"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks/DL_4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEDg4L5W7lYO"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all.zip\" -d \"//content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErW9fwiE7ld4"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DL_4/Test.zip\" -d \"//content/drive/My Drive/Colab Notebooks/DL_4/Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U491nJcutW0V"
      },
      "source": [
        "english_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all/AFEC-merged.en', encoding='utf8').read().split('\\n')\n",
        "persian_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all/AFEC-merged.fa', encoding='utf8').read().split('\\n')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW8YAVwmuYcb"
      },
      "source": [
        "data = {'English': [line for line in english_text],\n",
        "        'Persian': [line for line in persian_text ]}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6c4xzkR3EUT"
      },
      "source": [
        "df = pd.DataFrame(data ,  columns = ['English' , 'Persian'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3keeVT8m6GWF"
      },
      "source": [
        "train , validation = train_test_split(df , test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmycNtyH6GZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "88d2e89d-d42b-4296-9e3f-5bba4fca158e"
      },
      "source": [
        "train.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/train.json',orient='records' , lines =True)\n",
        "validation.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/validation.json',orient='records' , lines =True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/train.json',orient='records' , lines =True)\\nvalidation.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/validation.json',orient='records' , lines =True)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm6x9pTK-6rT"
      },
      "source": [
        "tokenizer = pyonmttok.Tokenizer(\"aggressive\", joiner_annotate = True , segment_numbers = True)\n",
        "learner_eng = pyonmttok.BPELearner(tokenizer = tokenizer , symbols = 3200)\n",
        "learner_per = pyonmttok.BPELearner(tokenizer = tokenizer , symbols = 3200)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1EKQ7kq-6tt"
      },
      "source": [
        "#english words\n",
        "for i in range(len(english_text)):\n",
        "    learner_eng.ingest(english_text[i])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phfxaNZm-63w"
      },
      "source": [
        "#persian wors\n",
        "for i in range(len(persian_text)):\n",
        "    learner_per.ingest(persian_text[i])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOm-2Gf8_sdO"
      },
      "source": [
        "path_eng = \"/content/drive/My Drive/Colab Notebooks/DL_4/model_english\"\n",
        "tokenizer_eng = learner_eng.learn(path_eng)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFmDsaiB_tV8"
      },
      "source": [
        "path_per = \"/content/drive/My Drive/Colab Notebooks/DL_4/model_persian\"\n",
        "tokenizer_per = learner_per.learn(path_per)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6tkmPPi_x2q",
        "outputId": "1ed26cb9-a45a-4a13-845a-335ff976f9c1"
      },
      "source": [
        "with open(path_eng) as model:\n",
        "    assert model.read() \n",
        "\n",
        "def tokenizer_english(text):\n",
        "  tokens, _ = tokenizer_eng.tokenize(text)\n",
        "  return tokens\n",
        "\n",
        "tokenizer_english(english_text[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['North', 'Waziristan', 'operation', 'kills', '5￭', '0', 'more', 'militants']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bUzSyyy_x5N",
        "outputId": "e8c9a92f-2d04-4980-a273-e58913c8ea82"
      },
      "source": [
        "with open(path_per) as model:\n",
        "    assert model.read() \n",
        "    \n",
        "def tokenizer_persian(text):\n",
        "  tokens ,_ = tokenizer_per.tokenize(text)\n",
        "  return tokens\n",
        "tokenizer_persian(persian_text[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مرگ', '5￭', '0', 'ستیزه', 'جوی', 'دیگر', 'در', 'عملیات', 'وزیرستان', 'شمالی']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEehwqdh_x7e"
      },
      "source": [
        "#Defines a datatype together with instructions for converting to Tensor.\n",
        "#sequentila -> if false no tokenize applied.\n",
        "#use_vocab : if false data already is numercal.\n",
        "\n",
        "english = Field(sequential = True , use_vocab = True ,init_token = '<sos>', eos_token = '<eos>',  batch_first = True, tokenize = tokenizer_english , lower = True)\n",
        "persian = Field(sequential = True , use_vocab = True ,init_token = '<sos>', eos_token = '<eos>',  batch_first = True, tokenize = tokenizer_persian , lower = True)\n",
        "\n",
        "            "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKvJjSyX7lqg"
      },
      "source": [
        "fields = {'English' : ('english',english), 'Persian' : ('persian',persian)}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1T6NsRFbbD"
      },
      "source": [
        "#Defines a Dataset of columns stored in CSV, TSV, or JSON format.\n",
        "train_data , validation_data = TabularDataset.splits(\n",
        "    path = '/content/drive/My Drive/Colab Notebooks/DL_4/',\n",
        "    train = 'train.json',\n",
        "    validation = 'validation.json',\n",
        "    format = 'json',\n",
        "    fields = fields\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVoaGYbKP6s"
      },
      "source": [
        "english.build_vocab(train_data , min_freq = 6)\n",
        "persian.build_vocab(train_data , min_freq = 6)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_I2T-m403Zz",
        "outputId": "42517ea0-2d2f-439c-de58-1f1ca3798868"
      },
      "source": [
        "len(english.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOdSJXfuKP8f"
      },
      "source": [
        "train_iterator , validation_iterator = BucketIterator.splits(\n",
        "    (train_data,validation_data),\n",
        "    batch_size = 64,\n",
        "    device='cuda',\n",
        "    sort = False\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP0LrnLiUe3W"
      },
      "source": [
        "Test **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk9H22FmUeQt"
      },
      "source": [
        "english_test_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.en', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_0 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa0', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_1 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa1', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_2 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa2', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_3 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa3', encoding='utf8').read().split('\\n')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaJI9goKLXJR"
      },
      "source": [
        "# **Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24onM_7LT2B5"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self ,embed_size , heads):\n",
        "    super(SelfAttention , self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.heads = heads\n",
        "    self.heads_dim = embed_size //heads\n",
        "    #print(self.heads_dim)\n",
        "\n",
        "    assert self.heads_dim*heads == embed_size ,\"Embed size need to be div by heads\"\n",
        "\n",
        "    \"\"\"self.values = nn.Linear(self.heads_dim , self.heads_dim , bias = False)\n",
        "    self.keys = nn.Linear(self.heads_dim , self.heads_dim ,bias = False)\n",
        "    self.queries = nn.Linear(self.heads_dim ,self.heads_dim , bias =False)\"\"\"\n",
        "\n",
        "    self.values = nn.Linear(self.embed_size , self.embed_size , bias = False)\n",
        "    self.keys = nn.Linear(self.embed_size , self.embed_size ,bias = False)\n",
        "    self.queries = nn.Linear(self.embed_size ,self.embed_size , bias =False)\n",
        "    self.fc_out = nn.Linear(heads*self.heads_dim , embed_size) #embed_size = heads*heads_dim\n",
        "\n",
        "\n",
        "  def forward(self , values , keys , queries , mask):\n",
        "    #number of training examples /how many example we are sending at the same time\n",
        "    N = queries.shape[0]\n",
        "    value_len , key_len , query_len = values.shape[1] , keys.shape[1] ,queries.shape[1] #these length coresspond to target and sourcr sentences length.\n",
        "    \n",
        "\n",
        "    values = self.values(values)\n",
        "    #print(\"after values\",values.shape)\n",
        "    keys = self.keys(keys)\n",
        "    #print(\"keys\",keys.shape)\n",
        "    queries = self.queries(queries)\n",
        "    #print(\"queries\" ,queries.shape)\n",
        "\n",
        "    #split embeddig into self.heads pieses\n",
        "    values = values.reshape(N , value_len , self.heads , self.heads_dim) # split embed_size into self.heads and self.heads_dim\n",
        "    #print(\"values\",values.shape)\n",
        "    keys = keys.reshape(N , key_len , self.heads , self.heads_dim)\n",
        "    queries = queries.reshape(N , query_len , self.heads , self.heads_dim)\n",
        "\n",
        "    energy = torch.einsum(\"bqhd,bkhd -> bhqk\" , [queries,keys])\n",
        "    #queiries shape: (N,query_len , heads , heads_dim)\n",
        "    #keys shape : (N , key_len ,heads ,heads_dim)\n",
        "    #energy shape : (N, heads , query_len , key_len) #query = target , key = source\n",
        "    #print(\"energy\",energy.shape)\n",
        "    if mask is not None:\n",
        "      #print(\"####mask\",mask.shape)\n",
        "      #print(\"energy\",energy.shape)\n",
        "      #mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "      #print(\"mask\",mask.shape)\n",
        "      mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "      energy = energy.masked_fill(mask == True , float(\"-1e20\"))#if a element of a mask is zero it means that shut that off\n",
        "      #print(\"energy after mask\",energy.shape)\n",
        "    #key_length = value_length\n",
        "    attention = torch.softmax(energy / (self.embed_size **(1/2)) , dim=2)\n",
        "    #print(\"attention\",attention.shape)\n",
        "    out = torch.einsum(\"bhql,blhd->bqhd\",[attention,values]).reshape(N,query_len,self.heads*self.heads_dim)\n",
        "    #print(\"out\",out.shape)\n",
        "    #attention shape :(batch,heads ,query_len ,key_len)\n",
        "    #values shape :(bach) ,value_len ,heads,head_dim)\n",
        "    #after einsum(batch,query_len,heads,head_dim) then flatten last two dimention\n",
        "\n",
        "    out = self.fc_out(out)\n",
        "    #print(\"selfattention\")\n",
        "    return out"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14D2mgTM1mRA"
      },
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size , embed_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "    def forward(self, tokens):\n",
        "\n",
        "        #print(\":tokenembedding\")\n",
        "        return self.embedding(tokens) * math.sqrt(self.embed_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7aX24RoYvvt"
      },
      "source": [
        "#https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size , maxlen = 500):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        den = torch.exp(- torch.arange(0, embed_size, 2)* math.log(10000) / embed_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, embed_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding ):\n",
        "        #print(\"positional_encoding\")\n",
        "        return self.pos_embedding[:token_embedding.size(0), :]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJbUZYqcesb"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,embed_size,heads,dropout,dim_inner):\n",
        "    super(TransformerBlock,self).__init__()\n",
        "    self.attention = SelfAttention(embed_size,heads)\n",
        "    self.norm1 = nn.LayerNorm(embed_size)\n",
        "    self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embed_size,dim_inner),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_inner,embed_size)\n",
        "    \n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,value , key, query, mask):\n",
        "    attention = self.attention(value,key,query,mask)\n",
        "\n",
        "    x = self.dropout(self.norm1(attention+query))\n",
        "    forward = self.feed_forward(x)\n",
        "    out = self.dropout(self.norm2(forward + x))\n",
        "    #print(\"transformerblock\")\n",
        "    return out"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqNI6OkxowKC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               src_vocab_size, \n",
        "               embed_size, \n",
        "               num_layers,\n",
        "               heads, \n",
        "               dim_inner,\n",
        "               device,\n",
        "               dropout,\n",
        "               max_length, #positional emedding how long is the sentence length\n",
        "  ):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.device = device\n",
        "    self.word_embedding = nn.Embedding(src_vocab_size , embed_size)\n",
        "    self.position_embedding = PositionalEncoding( embed_size ,max_length)\n",
        "\n",
        "    self.encoder_layers = nn.ModuleList(\n",
        "        [\n",
        "         TransformerBlock(\n",
        "             embed_size,\n",
        "             heads,\n",
        "             dropout = dropout,\n",
        "             dim_inner = dim_inner\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self , x , mask):\n",
        "    N, seq_length = x.shape\n",
        "    word_embedding = self.word_embedding(x)\n",
        "    pos_embedding = self.position_embedding(word_embedding)\n",
        "    out = self.dropout(word_embedding+pos_embedding)\n",
        "\n",
        "    for layer in self.encoder_layers:\n",
        "      out = layer(out , out , out, mask)\n",
        "    #print(\"out\",out.shape)\n",
        "    #print(\"encoder\")\n",
        "    return out"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK46aUd7t7-F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, embed_size, heads, num_layers ,trg_vocab_size,max_length ):\n",
        "    super(Decoder,self).__init__()\n",
        "    \n",
        "    self.embed_size = embed_size\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    #self.device = device\n",
        "    self.decoder_layers = nn.ModuleList(\n",
        "        [\n",
        "         nn.TransformerDecoderLayer(\n",
        "             d_model = embed_size,\n",
        "             nhead = heads,\n",
        "             batch_first = True\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.word_embedding = nn.Embedding(trg_vocab_size , embed_size)\n",
        "    self.position_embedding = PositionalEncoding( embed_size ,max_length)\n",
        "    self.fc_out = nn.Linear(embed_size, trg_vocab_size) \n",
        "\n",
        "  def forward(self , target , encoder_src, target_mask ,padding_mask ):\n",
        "\n",
        "    word_embedding = self.word_embedding(target)\n",
        "    pos_embedding = self.position_embedding(target)\n",
        "    out = self.dropout(word_embedding+pos_embedding)\n",
        "\n",
        "\n",
        "    for layer in self.decoder_layers:\n",
        "      out = layer( out, encoder_src ,tgt_mask  = target_mask ,tgt_key_padding_mask = padding_mask)\n",
        "    #print(\"decoder\")\n",
        "    out = self.fc_out(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mubv1yn7S1oU"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(\n",
        "      self, \n",
        "      encoder, \n",
        "      decoder, \n",
        "      src_pad_idx, \n",
        "      trg_pad_idx, \n",
        "      device\n",
        "  ):\n",
        "      super(Transformer , self).__init__()\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.src_pad_idx = src_pad_idx\n",
        "      self.trg_pad_idx = trg_pad_idx\n",
        "      self.device = device\n",
        "      self.pad_trg_idx = persian.vocab.stoi['<pad>']\n",
        "      self.pad_src_idx = english.vocab.stoi['<pad>']\n",
        "\n",
        "\n",
        "  def create_trg_mask(self ,tgt):\n",
        "      N , l = tgt.shape\n",
        "      mask = (torch.triu(torch.ones((l, l),device=self.device)) == 1).transpose(0, 1)\n",
        "      mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "      return mask.to(self.device)\n",
        "\n",
        "  def create_trg_padding_mask(self , tgt):\n",
        "    N , tgt_seq_len = tgt.shape\n",
        "    tgt_padding_mask = (tgt == self.pad_trg_idx)\n",
        "    return tgt_padding_mask.to(self.device)\n",
        "\n",
        "  def create_src_padding_mask(self , src):\n",
        "      src_seq_len = src.shape[1]\n",
        "      src_padding_mask = (src == self.pad_src_idx)\n",
        "      #src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n",
        "      return src_padding_mask.to(self.device)\n",
        "      \n",
        "\n",
        "  def forward(self, src, trg):\n",
        "\n",
        "      trg_mask =self.create_trg_mask(trg)\n",
        "      trg_mask.shape\n",
        "      trg_padding_mask =self.create_trg_padding_mask(trg)\n",
        "      trg_padding_mask.shape\n",
        "      src_padding_mask =self.create_src_padding_mask(src)\n",
        "      src_padding_mask.shape\n",
        "\n",
        "      enc_src = self.encoder(src, src_padding_mask)\n",
        "      out = self.decoder(trg, enc_src,trg_mask, trg_padding_mask)\n",
        "      #print(\"transformer\")\n",
        "      return out\n",
        "\n",
        "      "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ois8txdT0aLh"
      },
      "source": [
        "src_vocab_size = len(english.vocab)\n",
        "trg_vocab_size = len(persian.vocab)\n",
        "per_pad_idx = persian.vocab.stoi[persian.pad_token]\n",
        "eng_pad_idx = english.vocab.stoi[english.pad_token]\n",
        "embed_size = 256\n",
        "num_layers_enc = 3\n",
        "num_layers_dec = 3\n",
        "heads_enc = 8\n",
        "heads_dec = 8\n",
        "dim_inner = 1024\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dropout = 0.1\n",
        "max_length = 500\n",
        "\n",
        "encoder = Encoder(\n",
        "      src_vocab_size, \n",
        "      embed_size, \n",
        "      num_layers_enc, \n",
        "      heads_enc, \n",
        "      dim_inner,\n",
        "      device,\n",
        "      dropout,\n",
        "      max_length)\n",
        "\n",
        "decoder = Decoder(\n",
        "        embed_size,\n",
        "        heads_dec,\n",
        "        num_layers_dec,\n",
        "        trg_vocab_size,\n",
        "        max_length,\n",
        "        #batch_first = True\n",
        "    )\n",
        "\n",
        "model = Transformer(encoder, decoder, per_pad_idx, eng_pad_idx, device).to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMuSZ7j0CU5q"
      },
      "source": [
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuFz7ukN3aH6",
        "outputId": "21d5aff6-aa7f-4f8f-e9ea-48d73bbf8754"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,645,668 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7dMaWyxNdne"
      },
      "source": [
        "LearningRate = 0.0001"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGeQVXAjwvg"
      },
      "source": [
        "LearningRate = 0.0001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LearningRate,betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = per_pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k6seWAFMfNR"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(validation_iterator):\n",
        "\n",
        "            src = batch.english.to(device)\n",
        "            trg = batch.persian.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            output = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td2IpM173IEp",
        "outputId": "38e81d10-e294-4dfd-d979-b9717abd6f4d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "776bMPR_MfKx"
      },
      "source": [
        "def train(model, train_iterator,validation_iterator, optimizer, criterion, clip):\n",
        "\n",
        "    PATH = '/content/drive/My Drive/Colab Notebooks/DL4_part2_v1.pth'\n",
        "    model.train()\n",
        "    \n",
        "    loss_train = []\n",
        "    loss_val = []\n",
        "\n",
        "    iter_loss = 0\n",
        "    L = len(train_iterator)\n",
        "    flag = False\n",
        "    count_iter = 0\n",
        "\n",
        "    count_iter = 0\n",
        "    for epoch in range(10):\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            count_iter +=1\n",
        "\n",
        "            src = batch.english.to(device)\n",
        "            trg = batch.persian.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(src, trg[:,:-1]) #except last one\n",
        "                    \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "                \n",
        "            output_dim = output.shape[-1] #shape akhar\n",
        "                \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "                    \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "                \n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            iter_loss += loss.item()\n",
        "            #iter = epoch*L+i\n",
        "            if  count_iter%500== 0:\n",
        "  \n",
        "              loss_train.append(iter_loss/500)\n",
        "              temp = evaluate(model,validation_iterator,criterion)\n",
        "              loss_val.append(temp)\n",
        "              print(\"epoch:\",epoch+1,\"iteration:\",count_iter ,\"   train loss\" ,iter_loss/500 , \"   validation loss:\",temp)\n",
        "              iter_loss = 0\n",
        "\n",
        "            \n",
        "            if (count_iter) == 30000 :\n",
        "              flag = True\n",
        "              break\n",
        "            else:\n",
        "              continue\n",
        "        if flag == True:\n",
        "          break;\n",
        "              \n",
        "        torch.save(model.state_dict(), PATH)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH)\n",
        "    return model ,loss_train,loss_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgnriQrMMfRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1a53cb-e1fd-4765-e49c-71425fe69af1"
      },
      "source": [
        "model , train_loss,val_loss = train(model, train_iterator,validation_iterator, optimizer, criterion, clip=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 iteration: 500    train loss 4.084091748714447    validation loss: 3.5374528252075765\n",
            "epoch: 1 iteration: 1000    train loss 3.320100438117981    validation loss: 3.3407489859055137\n",
            "epoch: 1 iteration: 1500    train loss 3.27981924200058    validation loss: 3.3155697176389607\n",
            "epoch: 1 iteration: 2000    train loss 3.2681376576423644    validation loss: 3.2993105291206146\n",
            "epoch: 1 iteration: 2500    train loss 3.247595808506012    validation loss: 3.2812143111897405\n",
            "epoch: 1 iteration: 3000    train loss 3.240634624004364    validation loss: 3.2669113475585654\n",
            "epoch: 1 iteration: 3500    train loss 3.2162125940322874    validation loss: 3.257601042774236\n",
            "epoch: 1 iteration: 4000    train loss 3.209838613510132    validation loss: 3.2477090846712344\n",
            "epoch: 1 iteration: 4500    train loss 3.2000886816978453    validation loss: 3.229250258820079\n",
            "epoch: 1 iteration: 5000    train loss 3.1903098154067995    validation loss: 3.2252975412618334\n",
            "epoch: 1 iteration: 5500    train loss 3.1807942876815796    validation loss: 3.20829585556672\n",
            "epoch: 1 iteration: 6000    train loss 3.1780007915496826    validation loss: 3.1933744829391766\n",
            "epoch: 1 iteration: 6500    train loss 3.159623571395874    validation loss: 3.185804182346736\n",
            "epoch: 1 iteration: 7000    train loss 3.1516891045570374    validation loss: 3.1724185549210167\n",
            "epoch: 1 iteration: 7500    train loss 3.141950590610504    validation loss: 3.1657433253582394\n",
            "epoch: 1 iteration: 8000    train loss 3.128488480091095    validation loss: 3.1564896030960794\n",
            "epoch: 1 iteration: 8500    train loss 3.1237775611877443    validation loss: 3.146992826907434\n",
            "epoch: 1 iteration: 9000    train loss 3.1151097331047057    validation loss: 3.1365654065230184\n",
            "epoch: 1 iteration: 9500    train loss 3.1104145846366884    validation loss: 3.130539453141043\n",
            "epoch: 2 iteration: 10000    train loss 3.0659530391693117    validation loss: 3.1195611920312185\n",
            "epoch: 2 iteration: 10500    train loss 3.0438811535835266    validation loss: 3.111542065121303\n",
            "epoch: 2 iteration: 11000    train loss 3.0515416140556337    validation loss: 3.1044093992108497\n",
            "epoch: 2 iteration: 11500    train loss 3.037821820259094    validation loss: 3.094975480632247\n",
            "epoch: 2 iteration: 12000    train loss 3.025396397590637    validation loss: 3.0947029216267237\n",
            "epoch: 2 iteration: 12500    train loss 3.027704352378845    validation loss: 3.0818912813596637\n",
            "epoch: 2 iteration: 13000    train loss 3.0254433999061585    validation loss: 3.0808336881833656\n",
            "epoch: 2 iteration: 13500    train loss 3.020735174179077    validation loss: 3.067923364015383\n",
            "epoch: 2 iteration: 14000    train loss 3.0129891810417173    validation loss: 3.0571941295516827\n",
            "epoch: 2 iteration: 14500    train loss 2.9988029651641845    validation loss: 3.054581069946289\n",
            "epoch: 2 iteration: 15000    train loss 2.992774832725525    validation loss: 3.054161205024363\n",
            "epoch: 2 iteration: 15500    train loss 2.986223976612091    validation loss: 3.0392901792704503\n",
            "epoch: 2 iteration: 16000    train loss 2.988697139263153    validation loss: 3.0337824964077673\n",
            "epoch: 2 iteration: 16500    train loss 2.9779884066581728    validation loss: 3.029667974855298\n",
            "epoch: 2 iteration: 17000    train loss 2.9816226568222044    validation loss: 3.01960383308268\n",
            "epoch: 2 iteration: 17500    train loss 2.9680006356239317    validation loss: 3.0198143497805727\n",
            "epoch: 2 iteration: 18000    train loss 2.966395148277283    validation loss: 3.007275163347476\n",
            "epoch: 2 iteration: 18500    train loss 2.95773567533493    validation loss: 3.000272056989581\n",
            "epoch: 2 iteration: 19000    train loss 2.957229995727539    validation loss: 2.993058193732645\n",
            "epoch: 3 iteration: 19500    train loss 2.9176994342803955    validation loss: 2.9872485200935435\n",
            "epoch: 3 iteration: 20000    train loss 2.891088562488556    validation loss: 2.984673368596585\n",
            "epoch: 3 iteration: 20500    train loss 2.897834578037262    validation loss: 2.9844797121030147\n",
            "epoch: 3 iteration: 21000    train loss 2.898945049762726    validation loss: 2.9775509009851473\n",
            "epoch: 3 iteration: 21500    train loss 2.890006450176239    validation loss: 2.9707618483873173\n",
            "epoch: 3 iteration: 22000    train loss 2.8930113515853884    validation loss: 2.9663790778579\n",
            "epoch: 3 iteration: 22500    train loss 2.881167483329773    validation loss: 2.9619190626055283\n",
            "epoch: 3 iteration: 23000    train loss 2.8820123257637023    validation loss: 2.9604885832171575\n",
            "epoch: 3 iteration: 23500    train loss 2.8764898977279665    validation loss: 2.948657907726609\n",
            "epoch: 3 iteration: 24000    train loss 2.8772527327537536    validation loss: 2.9440410250815274\n",
            "epoch: 3 iteration: 24500    train loss 2.8794806332588196    validation loss: 2.9426347667925827\n",
            "epoch: 3 iteration: 25000    train loss 2.870227715015411    validation loss: 2.936226294419476\n",
            "epoch: 3 iteration: 25500    train loss 2.8681949949264527    validation loss: 2.9353981058174203\n",
            "epoch: 3 iteration: 26000    train loss 2.870514686584473    validation loss: 2.9257192353221857\n",
            "epoch: 3 iteration: 26500    train loss 2.8585971574783327    validation loss: 2.921751116592193\n",
            "epoch: 3 iteration: 27000    train loss 2.8622577252388    validation loss: 2.9181095878654553\n",
            "epoch: 3 iteration: 27500    train loss 2.84894139957428    validation loss: 2.9142053646461985\n",
            "epoch: 3 iteration: 28000    train loss 2.8547869062423707    validation loss: 2.9070527275031974\n",
            "epoch: 3 iteration: 28500    train loss 2.8425731015205384    validation loss: 2.903617245237404\n",
            "epoch: 4 iteration: 29000    train loss 2.8273629240989684    validation loss: 2.8980433579917264\n",
            "epoch: 4 iteration: 29500    train loss 2.785678713798523    validation loss: 2.896119589449089\n",
            "epoch: 4 iteration: 30000    train loss 2.7782517738342287    validation loss: 2.895092076007451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8kb-qzAdinrj",
        "outputId": "045a3b7e-1f80-4de3-be12-90cfeaab1004"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss )\n",
        "plt.plot(val_loss)\n",
        "plt.title('Loss function per Iteration')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train','val']);"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbox8rflIaDp"
      },
      "source": [
        "\"\"\"PATH = '/content/drive/My Drive/Colab Notebooks/DL4_part2_v1.pth'\n",
        "\n",
        "model = Transformer(encoder, decoder, per_pad_idx, eng_pad_idx, device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LearningRate,betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "model.train()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJeXQ47TGWD"
      },
      "source": [
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S82rLNifIagb"
      },
      "source": [
        "def translation(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.create_src_padding_mask(src_tensor)\n",
        "       \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "      \n",
        "\n",
        "        trg_padding_mask =  model.create_trg_padding_mask(trg_tensor)\n",
        "        trg_mask =   model.create_trg_mask(trg_tensor)\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(trg_tensor, enc_src, trg_mask, trg_padding_mask )\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukxen_cQOvgp"
      },
      "source": [
        "example_idx = 65\n",
        "#65, 45 , 154 , 89\n",
        "def view_sentence(example_idx):\n",
        "    src = english_test_text[example_idx]\n",
        "    trg = persian_test_text_0[example_idx]\n",
        "\n",
        "    print('English(source):' ,\"\".join(src[:-1]))\n",
        "    print('persian(target):',\"\".join(trg[:-1]) )\n",
        "    predict = translation(src, english, persian, model, device)\n",
        "    print(\"predict:\" ,\" \".join(predict[:-1]) )"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJTMOTYBO74z",
        "outputId": "c5bf474c-4b2c-48ba-b786-157c2bb8f464"
      },
      "source": [
        "a = [1 , 102,107,215,65 ,89 , 156,182,18,51]\n",
        "for i in a:\n",
        "  view_sentence(i)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English(source): it is more comfortable by train \n",
            "persian(target): با قطار خیلی راحتتر است \n",
            "predict: بیشتر از آن بیشتر است .\n",
            "\n",
            "\n",
            "English(source): would you like to do something in the evening \n",
            "persian(target): آیا عصر دوست دارید کاری انجام دهید \n",
            "predict: کاری که می￭ کنی انجام ب￭ دهید ?\n",
            "\n",
            "\n",
            "English(source): okay . goodbye \n",
            "persian(target): باشه . خداحافظ \n",
            "predict: .\n",
            "\n",
            "\n",
            "English(source): yes , I would suggest the flight at a quarter past seven \n",
            "persian(target): بله ، من پرواز ساعت هفت و ربع را پیشنهاد میکنم \n",
            "predict: بله , من در ساعت هفت و یک ساعت در یک ر￭ اس￭ تا هستم .\n",
            "\n",
            "\n",
            "English(source): I did not understand that \n",
            "persian(target): من آن را نفهمیدم \n",
            "predict: من آن را ن￭ کردم .\n",
            "\n",
            "\n",
            "English(source): what is the name of our hotel \n",
            "persian(target): نام هتل ما چیست \n",
            "predict: اسم ما چه است ?\n",
            "\n",
            "\n",
            "English(source): yes . is everything okay so far then \n",
            "persian(target): بله . پس تا به حال همه چیز مرتب است \n",
            "predict: بله , همه چیز بسیار خوب است ? بله .\n",
            "\n",
            "\n",
            "English(source): fine . let us meet at ten o'clock in the morning . should we go by train \n",
            "persian(target): خوب است . اجازه دهید ساعت ده صبح ملاقات کنیم . آیا باید با قطار برویم \n",
            "predict: خوب است , پس بگذار￭ ید ساعت ده صبح را ملاقات کنیم ? پس بگذار￭ یم .\n",
            "\n",
            "\n",
            "English(source): no idea . we will see . it does not matter \n",
            "persian(target): نظری ندارم . یکدیگر را میبینیم . مهم نیست \n",
            "predict: ایده ￭‌￭ ای نیست . ایده ￭‌￭ ای است .\n",
            "\n",
            "\n",
            "English(source): fine , would you like to do something in the evening \n",
            "persian(target): خوب ، آیا دوست داری عصر کاری انجام دهی \n",
            "predict: آیا کاری را در این صورت می￭ تو￭ نید ?\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4JFTAsoMfYO"
      },
      "source": [
        "def make_hypotheses(example_idx):\n",
        "    src = english_test_text[example_idx]\n",
        "    trg = persian_test_text_0[example_idx]\n",
        "\n",
        "    predict = translation(src, english, persian, model, device)\n",
        "    return (predict[:-1])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fyvaGclyvXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed195f48-2cbc-41b3-b568-aba8057d8685"
      },
      "source": [
        "#import nltk.tranlate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu \n",
        "from nltk.translate.nist_score import corpus_nist\n",
        "\n",
        "bleu_2 = []\n",
        "bleu_3 = []\n",
        "bleu_4 = []\n",
        "nist = []\n",
        "\n",
        "for i in range(len(persian_test_text_0)):\n",
        "  hypotheses = []\n",
        "  refrences = []\n",
        "\n",
        "  hypotheses.append(make_hypotheses(i))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_0[i]))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_1[i]))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_2[i]))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_3[i]))\n",
        "  #print(refrences)\n",
        "  weights = (1./5., 1./5., 1./5., 1./5.)\n",
        "  bleu_4.append(corpus_bleu([refrences],hypotheses, weights)) \n",
        "  weights = (1./5., 1./5., 1./5.)\n",
        "  bleu_3.append(corpus_bleu([refrences],hypotheses, weights))\n",
        "  weights = (1./5., 1./5.)\n",
        "  bleu_2.append(corpus_bleu([refrences],hypotheses, weights)) \n",
        "  if i in [5,8,21 , 39 ,46 ,60 , 64 , 69 ,89 ,99 ,107,179,192,216,219,250]:\n",
        "    continue\n",
        "  try :\n",
        "      try :\n",
        "          nist.append(corpus_nist([refrences],hypotheses)) \n",
        "      except  StopIteration:\n",
        "          nist.append(0)\n",
        "  except  ZeroDivisionError:\n",
        "      nist.append(0)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3uWPly_YDCX",
        "outputId": "2d750295-1fbe-4ac4-c96b-bcf5a1692fb9"
      },
      "source": [
        "np.mean(bleu_2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33444979059823704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWCNOuB3YDD2",
        "outputId": "7b792610-9731-44fa-fda0-8836294236cf"
      },
      "source": [
        "np.mean(bleu_3)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13723654610607663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p53FuWBYDI4",
        "outputId": "fdaf0a90-04ac-4345-c9e9-2c08f8964ec4"
      },
      "source": [
        "np.mean(bleu_4)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03657478465766052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62t-kdAOYJhy",
        "outputId": "0e692f16-0966-4916-e2eb-6cba597271f8"
      },
      "source": [
        "np.mean(nist)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9686251403740994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}