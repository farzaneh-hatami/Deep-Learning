{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_part1_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IOB4XiizglA",
        "outputId": "535caa0b-9633-48e5-ec56-5d09bd571090"
      },
      "source": [
        "pip install hazm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 9.4MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 52.4MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n",
            "Building wheels for collected packages: libwapiti, nltk\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154160 sha256=bab06b00988431e7801f37ea5ba91b7b427c2410a4def070c4376603c5507554\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394488 sha256=ddae0953e86821ff80d12ccbe910c950b2ad075b5de3db5fa52170b4fe3e5721\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built libwapiti nltk\n",
            "Installing collected packages: libwapiti, nltk, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OjKit5PRVNe"
      },
      "source": [
        "# Train and validation processing using torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln1NpZEyjcHg"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch \n",
        "import requests\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "from hazm import *\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXfx5UQGtS4",
        "outputId": "32f19dab-7609-4ac5-a305-708f6de8225d"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "n7sAAZLfjEhn",
        "outputId": "f81a4fca-27a4-4d73-efad-6585e3be265c"
      },
      "source": [
        "!pip install  --upgrade nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "\u001b[31mERROR: hazm 0.7.0 has requirement nltk==3.3, but you'll have nltk 3.6.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.3\n",
            "    Uninstalling nltk-3.3:\n",
            "      Successfully uninstalled nltk-3.3\n",
            "Successfully installed nltk-3.6.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huEQHXpGjjfC",
        "outputId": "f469c4f3-d26d-416f-9377-feacd2575b5e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMwBHXEs7lML"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks/DL_4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEDg4L5W7lYO"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all.zip\" -d \"//content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErW9fwiE7ld4"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DL_4/Test.zip\" -d \"//content/drive/My Drive/Colab Notebooks/DL_4/Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U491nJcutW0V"
      },
      "source": [
        "english_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all/AFEC-merged.en', encoding='utf8').read().split('\\n')\n",
        "persian_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all/AFEC-merged.fa', encoding='utf8').read().split('\\n')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW8YAVwmuYcb"
      },
      "source": [
        "data = {'English': [line for line in english_text],\n",
        "        'Persian': [line for line in persian_text ]}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6c4xzkR3EUT"
      },
      "source": [
        "df = pd.DataFrame(data ,  columns = ['English' , 'Persian'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3keeVT8m6GWF"
      },
      "source": [
        "train , validation = train_test_split(df , test_size = 0.1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmycNtyH6GZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "88d2e89d-d42b-4296-9e3f-5bba4fca158e"
      },
      "source": [
        "train.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/train.json',orient='records' , lines =True)\n",
        "validation.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/validation.json',orient='records' , lines =True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/train.json',orient='records' , lines =True)\\nvalidation.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/validation.json',orient='records' , lines =True)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKxlHFhG7lhF"
      },
      "source": [
        "def tokenize_english(text):\n",
        "      return  word_tokenize(text.lower()) #lower case vocabs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFGODc3y7lkV"
      },
      "source": [
        "def tokenize_persian(text):\n",
        "      return  word_tokenize(text) #lower case vocabs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VEq0Wx67lni"
      },
      "source": [
        "#Defines a datatype together with instructions for converting to Tensor.\n",
        "#sequentila -> if false no tokenize applied.\n",
        "#use_vocab : if false data already is numercal.\n",
        "\n",
        "english = Field(sequential = True , use_vocab = True ,init_token = '<sos>', eos_token = '<eos>',  batch_first = True, tokenize = tokenize_english , lower = True)\n",
        "persian = Field(sequential = True , use_vocab = True ,init_token = '<sos>', eos_token = '<eos>',  batch_first = True, tokenize = tokenize_persian , lower = True)\n",
        "\n",
        "            "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKvJjSyX7lqg"
      },
      "source": [
        "fields = {'English' : ('english',english), 'Persian' : ('persian',persian)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1T6NsRFbbD"
      },
      "source": [
        "#Defines a Dataset of columns stored in CSV, TSV, or JSON format.\n",
        "train_data , validation_data = TabularDataset.splits(\n",
        "    path = '/content/drive/My Drive/Colab Notebooks/DL_4/',\n",
        "    train = 'train.json',\n",
        "    validation = 'validation.json',\n",
        "    format = 'json',\n",
        "    fields = fields\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVoaGYbKP6s"
      },
      "source": [
        "english.build_vocab(train_data , min_freq = 6)\n",
        "persian.build_vocab(train_data , min_freq = 6)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_I2T-m403Zz",
        "outputId": "b7c3758f-f5c2-4e0e-b541-ad39ad093ebb"
      },
      "source": [
        "len(english.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOdSJXfuKP8f"
      },
      "source": [
        "train_iterator , validation_iterator = BucketIterator.splits(\n",
        "    (train_data,validation_data),\n",
        "    batch_size = 64,\n",
        "    device='cuda',\n",
        "    sort = False\n",
        "  \n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP0LrnLiUe3W"
      },
      "source": [
        "Test **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk9H22FmUeQt"
      },
      "source": [
        "english_test_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.en', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_0 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa0', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_1 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa1', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_2 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa2', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_3 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa3', encoding='utf8').read().split('\\n')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LShuE1HhcCZQ",
        "outputId": "9a4906fd-c65e-446b-a4f8-6ffde24f3256"
      },
      "source": [
        "persian_test_text_0[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'سلام ، آیا روز بیست و هشتم مارچ قرار است با هم تا هانوور رانندگی کنیم ؟'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaJI9goKLXJR"
      },
      "source": [
        "# **Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24onM_7LT2B5"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self ,embed_size , heads):\n",
        "    super(SelfAttention , self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.heads = heads\n",
        "    self.heads_dim = embed_size //heads\n",
        "    #print(self.heads_dim)\n",
        "\n",
        "    assert self.heads_dim*heads == embed_size ,\"Embed size need to be div by heads\"\n",
        "\n",
        "    \"\"\"self.values = nn.Linear(self.heads_dim , self.heads_dim , bias = False)\n",
        "    self.keys = nn.Linear(self.heads_dim , self.heads_dim ,bias = False)\n",
        "    self.queries = nn.Linear(self.heads_dim ,self.heads_dim , bias =False)\"\"\"\n",
        "\n",
        "    self.values = nn.Linear(self.embed_size , self.embed_size , bias = False)\n",
        "    self.keys = nn.Linear(self.embed_size , self.embed_size ,bias = False)\n",
        "    self.queries = nn.Linear(self.embed_size ,self.embed_size , bias =False)\n",
        "    self.fc_out = nn.Linear(heads*self.heads_dim , embed_size) #embed_size = heads*heads_dim\n",
        "\n",
        "\n",
        "  def forward(self , values , keys , queries , mask):\n",
        "    #number of training examples /how many example we are sending at the same time\n",
        "    N = queries.shape[0]\n",
        "    value_len , key_len , query_len = values.shape[1] , keys.shape[1] ,queries.shape[1] #these length coresspond to target and sourcr sentences length.\n",
        "    \n",
        "\n",
        "    values = self.values(values)\n",
        "    #print(\"after values\",values.shape)\n",
        "    keys = self.keys(keys)\n",
        "    #print(\"keys\",keys.shape)\n",
        "    queries = self.queries(queries)\n",
        "    #print(\"queries\" ,queries.shape)\n",
        "\n",
        "    #split embeddig into self.heads pieses\n",
        "    values = values.reshape(N , value_len , self.heads , self.heads_dim) # split embed_size into self.heads and self.heads_dim\n",
        "    #print(\"values\",values.shape)\n",
        "    keys = keys.reshape(N , key_len , self.heads , self.heads_dim)\n",
        "    queries = queries.reshape(N , query_len , self.heads , self.heads_dim)\n",
        "\n",
        "    energy = torch.einsum(\"bqhd,bkhd -> bhqk\" , [queries,keys])\n",
        "    #queiries shape: (N,query_len , heads , heads_dim)\n",
        "    #keys shape : (N , key_len ,heads ,heads_dim)\n",
        "    #energy shape : (N, heads , query_len , key_len) #query = target , key = source\n",
        "    #print(\"energy\",energy.shape)\n",
        "    if mask is not None:\n",
        "      #print(\"####mask\",mask.shape)\n",
        "      #print(\"energy\",energy.shape)\n",
        "      #mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "      #print(\"mask\",mask.shape)\n",
        "      mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "      energy = energy.masked_fill(mask == True , float(\"-1e20\"))#if a element of a mask is zero it means that shut that off\n",
        "      #print(\"energy after mask\",energy.shape)\n",
        "    #key_length = value_length\n",
        "    attention = torch.softmax(energy / (self.embed_size **(1/2)) , dim=2)\n",
        "    #print(\"attention\",attention.shape)\n",
        "    out = torch.einsum(\"bhql,blhd->bqhd\",[attention,values]).reshape(N,query_len,self.heads*self.heads_dim)\n",
        "    #print(\"out\",out.shape)\n",
        "    #attention shape :(batch,heads ,query_len ,key_len)\n",
        "    #values shape :(bach) ,value_len ,heads,head_dim)\n",
        "    #after einsum(batch,query_len,heads,head_dim) then flatten last two dimention\n",
        "\n",
        "    out = self.fc_out(out)\n",
        "    #print(\"selfattention\")\n",
        "    return out"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14D2mgTM1mRA"
      },
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size , embed_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "    def forward(self, tokens):\n",
        "\n",
        "        #print(\":tokenembedding\")\n",
        "        return self.embedding(tokens) * math.sqrt(self.embed_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7aX24RoYvvt"
      },
      "source": [
        "#https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size , maxlen = 500):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        den = torch.exp(- torch.arange(0, embed_size, 2)* math.log(10000) / embed_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, embed_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding ):\n",
        "        #print(\"positional_encoding\")\n",
        "        return self.pos_embedding[:token_embedding.size(0), :]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJbUZYqcesb"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,embed_size,heads,dropout,dim_inner):\n",
        "    super(TransformerBlock,self).__init__()\n",
        "    self.attention = SelfAttention(embed_size,heads)\n",
        "    self.norm1 = nn.LayerNorm(embed_size)\n",
        "    self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embed_size,dim_inner),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_inner,embed_size)\n",
        "    \n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,value , key, query, mask):\n",
        "    attention = self.attention(value,key,query,mask)\n",
        "\n",
        "    x = self.dropout(self.norm1(attention+query))\n",
        "    forward = self.feed_forward(x)\n",
        "    out = self.dropout(self.norm2(forward + x))\n",
        "    #print(\"transformerblock\")\n",
        "    return out"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqNI6OkxowKC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               src_vocab_size, \n",
        "               embed_size, \n",
        "               num_layers,\n",
        "               heads, \n",
        "               dim_inner,\n",
        "               device,\n",
        "               dropout,\n",
        "               max_length, #positional emedding how long is the sentence length\n",
        "  ):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.device = device\n",
        "    self.word_embedding = nn.Embedding(src_vocab_size , embed_size)\n",
        "    self.position_embedding = PositionalEncoding( embed_size ,max_length)\n",
        "\n",
        "    self.encoder_layers = nn.ModuleList(\n",
        "        [\n",
        "         TransformerBlock(\n",
        "             embed_size,\n",
        "             heads,\n",
        "             dropout = dropout,\n",
        "             dim_inner = dim_inner\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self , x , mask):\n",
        "    N, seq_length = x.shape\n",
        "    word_embedding = self.word_embedding(x)\n",
        "    pos_embedding = self.position_embedding(word_embedding)\n",
        "    out = self.dropout(word_embedding+pos_embedding)\n",
        "\n",
        "    for layer in self.encoder_layers:\n",
        "      out = layer(out , out , out, mask)\n",
        "    #print(\"out\",out.shape)\n",
        "    #print(\"encoder\")\n",
        "    return out"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK46aUd7t7-F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, embed_size, heads, num_layers ,trg_vocab_size,max_length ):\n",
        "    super(Decoder,self).__init__()\n",
        "    \n",
        "    self.embed_size = embed_size\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    #self.device = device\n",
        "    self.decoder_layers = nn.ModuleList(\n",
        "        [\n",
        "         nn.TransformerDecoderLayer(\n",
        "             d_model = embed_size,\n",
        "             nhead = heads,\n",
        "             batch_first = True\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.word_embedding = nn.Embedding(trg_vocab_size , embed_size)\n",
        "    self.position_embedding = PositionalEncoding( embed_size ,max_length)\n",
        "    self.fc_out = nn.Linear(embed_size, trg_vocab_size) \n",
        "\n",
        "  def forward(self , target , encoder_src, target_mask ,padding_mask ):\n",
        "\n",
        "    word_embedding = self.word_embedding(target)\n",
        "    pos_embedding = self.position_embedding(target)\n",
        "    out = self.dropout(word_embedding+pos_embedding)\n",
        "\n",
        "\n",
        "    for layer in self.decoder_layers:\n",
        "      out = layer( out, encoder_src ,tgt_mask  = target_mask ,tgt_key_padding_mask = padding_mask)\n",
        "    #print(\"decoder\")\n",
        "    out = self.fc_out(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mubv1yn7S1oU"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(\n",
        "      self, \n",
        "      encoder, \n",
        "      decoder, \n",
        "      src_pad_idx, \n",
        "      trg_pad_idx, \n",
        "      device\n",
        "  ):\n",
        "      super(Transformer , self).__init__()\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.src_pad_idx = src_pad_idx\n",
        "      self.trg_pad_idx = trg_pad_idx\n",
        "      self.device = device\n",
        "      self.pad_trg_idx = persian.vocab.stoi['<pad>']\n",
        "      self.pad_src_idx = english.vocab.stoi['<pad>']\n",
        "\n",
        "\n",
        "\n",
        "  def create_trg_mask(self ,tgt):\n",
        "      N , l = tgt.shape\n",
        "      mask = (torch.triu(torch.ones((l, l),device=self.device)) == 1).transpose(0, 1)\n",
        "      mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "      return mask.to(self.device)\n",
        "\n",
        "  def create_trg_padding_mask(self , tgt):\n",
        "    N , tgt_seq_len = tgt.shape\n",
        "    tgt_padding_mask = (tgt == self.pad_trg_idx)\n",
        "    return tgt_padding_mask.to(self.device)\n",
        "\n",
        "  def create_src_padding_mask(self , src):\n",
        "      src_seq_len = src.shape[1]\n",
        "      src_padding_mask = (src == self.pad_src_idx)\n",
        "      #src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n",
        "      return src_padding_mask.to(self.device)\n",
        "      \n",
        "\n",
        "  def forward(self, src, trg):\n",
        "\n",
        "      trg_mask =self.create_trg_mask(trg)\n",
        "      trg_mask.shape\n",
        "      trg_padding_mask =self.create_trg_padding_mask(trg)\n",
        "      trg_padding_mask.shape\n",
        "      src_padding_mask =self.create_src_padding_mask(src)\n",
        "      src_padding_mask.shape\n",
        "\n",
        "      enc_src = self.encoder(src, src_padding_mask)\n",
        "      out = self.decoder(trg, enc_src,trg_mask, trg_padding_mask)\n",
        "      #print(\"transformer\")\n",
        "      return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ois8txdT0aLh"
      },
      "source": [
        "src_vocab_size = len(english.vocab)\n",
        "trg_vocab_size = len(persian.vocab)\n",
        "per_pad_idx = persian.vocab.stoi[persian.pad_token]\n",
        "eng_pad_idx = english.vocab.stoi[english.pad_token]\n",
        "embed_size = 256\n",
        "num_layers_enc = 3\n",
        "num_layers_dec = 3\n",
        "heads_enc = 8\n",
        "heads_dec = 8\n",
        "dim_inner = 1024\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dropout = 0.1\n",
        "max_length = 500\n",
        "\n",
        "encoder = Encoder(\n",
        "      src_vocab_size, \n",
        "      embed_size, \n",
        "      num_layers_enc, \n",
        "      heads_enc, \n",
        "      dim_inner,\n",
        "      device,\n",
        "      dropout,\n",
        "      max_length)\n",
        "\n",
        "decoder = Decoder(\n",
        "        embed_size,\n",
        "        heads_dec,\n",
        "        num_layers_dec,\n",
        "        trg_vocab_size,\n",
        "        max_length,\n",
        "        #batch_first = True\n",
        "    )\n",
        "\n",
        "model = Transformer(encoder, decoder, per_pad_idx, eng_pad_idx, device).to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuFz7ukN3aH6",
        "outputId": "f2c12c1f-310e-4312-b89f-1855c8341f90"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 37,284,250 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7dMaWyxNdne"
      },
      "source": [
        "LearningRate = 0.0001"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGeQVXAjwvg"
      },
      "source": [
        "LearningRate = 0.0001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LearningRate,betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = per_pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k6seWAFMfNR"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(validation_iterator):\n",
        "\n",
        "            src = batch.english.to(device)\n",
        "            trg = batch.persian.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            output = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "776bMPR_MfKx"
      },
      "source": [
        "def train(model, train_iterator,validation_iterator, optimizer, criterion, clip):\n",
        "\n",
        "    PATH = '/content/drive/My Drive/Colab Notebooks/DL4_v2.pth'\n",
        "    model.train()\n",
        "    \n",
        "    loss_train = []\n",
        "    loss_val = []\n",
        "\n",
        "    iter_loss = 0\n",
        "    L = len(train_iterator)\n",
        "    flag = False\n",
        "    count_iter = 0\n",
        "\n",
        "    count_iter = 0\n",
        "    for epoch in range(10):\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            count_iter +=1\n",
        "\n",
        "            src = batch.english.to(device)\n",
        "            trg = batch.persian.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(src, trg[:,:-1]) #except last one\n",
        "                    \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "                \n",
        "            output_dim = output.shape[-1] #shape akhar\n",
        "                \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "                    \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "                \n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            iter_loss += loss.item()\n",
        "            #iter = epoch*L+i\n",
        "            if  count_iter%500== 0:\n",
        "  \n",
        "              loss_train.append(iter_loss/500)\n",
        "              temp = evaluate(model,validation_iterator,criterion)\n",
        "              loss_val.append(temp)\n",
        "              print(\"epoch:\",epoch+1,\"iteration:\",count_iter ,\"   train loss\" ,iter_loss/500 , \"   validation loss:\",temp)\n",
        "              iter_loss = 0\n",
        "\n",
        "            \n",
        "            if (count_iter) == 30000 :\n",
        "              flag = True\n",
        "              break\n",
        "            else:\n",
        "              continue\n",
        "        if flag == True:\n",
        "          break;\n",
        "              \n",
        "        torch.save(model.state_dict(), PATH)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH)\n",
        "    return model ,loss_train,loss_val"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgnriQrMMfRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd34607-4fcb-4ff4-e5fe-ba55adf0e03a"
      },
      "source": [
        "model , train_loss,val_loss = train(model, train_iterator,validation_iterator, optimizer, criterion, clip=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 iteration: 500    train loss 7.116504956245422    validation loss: 6.446265857019157\n",
            "epoch: 1 iteration: 1000    train loss 6.256436658859253    validation loss: 6.0451476997304185\n",
            "epoch: 1 iteration: 1500    train loss 5.936145414352417    validation loss: 5.7831427449377895\n",
            "epoch: 1 iteration: 2000    train loss 5.708330180168152    validation loss: 5.588591148251685\n",
            "epoch: 1 iteration: 2500    train loss 5.53790795135498    validation loss: 5.450668221767818\n",
            "epoch: 1 iteration: 3000    train loss 5.38975368309021    validation loss: 5.3070092022976025\n",
            "epoch: 1 iteration: 3500    train loss 5.266113642692566    validation loss: 5.201215827799289\n",
            "epoch: 1 iteration: 4000    train loss 5.167408588409423    validation loss: 5.088755754221266\n",
            "epoch: 1 iteration: 4500    train loss 5.0684644956588745    validation loss: 5.001639703946693\n",
            "epoch: 1 iteration: 5000    train loss 4.986650184631348    validation loss: 4.926167437740576\n",
            "epoch: 1 iteration: 5500    train loss 4.911217530250549    validation loss: 4.854001604062375\n",
            "epoch: 1 iteration: 6000    train loss 4.845659814834595    validation loss: 4.791567047511306\n",
            "epoch: 1 iteration: 6500    train loss 4.78177400302887    validation loss: 4.7454296165537615\n",
            "epoch: 1 iteration: 7000    train loss 4.729224957466125    validation loss: 4.683976154683906\n",
            "epoch: 1 iteration: 7500    train loss 4.669631434440613    validation loss: 4.643192061308389\n",
            "epoch: 1 iteration: 8000    train loss 4.636149793624878    validation loss: 4.586602670901289\n",
            "epoch: 1 iteration: 8500    train loss 4.586852121353149    validation loss: 4.545628025821436\n",
            "epoch: 1 iteration: 9000    train loss 4.546393363952637    validation loss: 4.528928150194828\n",
            "epoch: 1 iteration: 9500    train loss 4.513555378913879    validation loss: 4.474704176020399\n",
            "epoch: 2 iteration: 10000    train loss 4.45186396408081    validation loss: 4.43431187611874\n",
            "epoch: 2 iteration: 10500    train loss 4.404650925159454    validation loss: 4.40631829823289\n",
            "epoch: 2 iteration: 11000    train loss 4.377531103134155    validation loss: 4.384011699774555\n",
            "epoch: 2 iteration: 11500    train loss 4.336834662437439    validation loss: 4.350334072335858\n",
            "epoch: 2 iteration: 12000    train loss 4.325884677410126    validation loss: 4.330019591679083\n",
            "epoch: 2 iteration: 12500    train loss 4.303686000823975    validation loss: 4.295520739911873\n",
            "epoch: 2 iteration: 13000    train loss 4.270075496673584    validation loss: 4.272823432672804\n",
            "epoch: 2 iteration: 13500    train loss 4.258529445648193    validation loss: 4.251708856921329\n",
            "epoch: 2 iteration: 14000    train loss 4.239287559509277    validation loss: 4.222281569409593\n",
            "epoch: 2 iteration: 14500    train loss 4.212308791160583    validation loss: 4.203316685418102\n",
            "epoch: 2 iteration: 15000    train loss 4.178909331321717    validation loss: 4.18367494066185\n",
            "epoch: 2 iteration: 15500    train loss 4.163729854106903    validation loss: 4.16846046670575\n",
            "epoch: 2 iteration: 16000    train loss 4.140655071258545    validation loss: 4.140636921374598\n",
            "epoch: 2 iteration: 16500    train loss 4.114585959911347    validation loss: 4.129856474377284\n",
            "epoch: 2 iteration: 17000    train loss 4.108972409248352    validation loss: 4.107244357884487\n",
            "epoch: 2 iteration: 17500    train loss 4.105155398845673    validation loss: 4.09084284416983\n",
            "epoch: 2 iteration: 18000    train loss 4.0765013890266415    validation loss: 4.062926820059803\n",
            "epoch: 2 iteration: 18500    train loss 4.059008172512055    validation loss: 4.050907819961833\n",
            "epoch: 2 iteration: 19000    train loss 4.044356091022491    validation loss: 4.033947021047646\n",
            "epoch: 3 iteration: 19500    train loss 3.988612367630005    validation loss: 4.020874009399771\n",
            "epoch: 3 iteration: 20000    train loss 3.963955204963684    validation loss: 4.003442836921906\n",
            "epoch: 3 iteration: 20500    train loss 3.9464571332931517    validation loss: 3.995153647494093\n",
            "epoch: 3 iteration: 21000    train loss 3.9225896339416506    validation loss: 3.98549051485329\n",
            "epoch: 3 iteration: 21500    train loss 3.9189381465911866    validation loss: 3.971874635464677\n",
            "epoch: 3 iteration: 22000    train loss 3.9306424703598024    validation loss: 3.952319613572593\n",
            "epoch: 3 iteration: 22500    train loss 3.9036118288040162    validation loss: 3.9441649655315363\n",
            "epoch: 3 iteration: 23000    train loss 3.892038643836975    validation loss: 3.9271152242321836\n",
            "epoch: 3 iteration: 23500    train loss 3.887972584247589    validation loss: 3.912514463986192\n",
            "epoch: 3 iteration: 24000    train loss 3.8678965649604797    validation loss: 3.901074921527756\n",
            "epoch: 3 iteration: 24500    train loss 3.8643669986724856    validation loss: 3.90114332782888\n",
            "epoch: 3 iteration: 25000    train loss 3.8575988388061524    validation loss: 3.892384017962162\n",
            "epoch: 3 iteration: 25500    train loss 3.845425576210022    validation loss: 3.87313957526305\n",
            "epoch: 3 iteration: 26000    train loss 3.83901349067688    validation loss: 3.858881187438965\n",
            "epoch: 3 iteration: 26500    train loss 3.8148097443580626    validation loss: 3.853483372091133\n",
            "epoch: 3 iteration: 27000    train loss 3.8178640489578246    validation loss: 3.8516492115002925\n",
            "epoch: 3 iteration: 27500    train loss 3.8093827891349794    validation loss: 3.831674192999011\n",
            "epoch: 3 iteration: 28000    train loss 3.8068966155052184    validation loss: 3.8230584594690913\n",
            "epoch: 3 iteration: 28500    train loss 3.798307089328766    validation loss: 3.812063636958042\n",
            "epoch: 4 iteration: 29000    train loss 3.7517711515426635    validation loss: 3.798478108700191\n",
            "epoch: 4 iteration: 29500    train loss 3.6928147888183593    validation loss: 3.788444621763497\n",
            "epoch: 4 iteration: 30000    train loss 3.7017907490730284    validation loss: 3.7829153542206666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XPN1H-7f2X5N",
        "outputId": "d4566654-167e-456b-f13b-0b9623465833"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss )\n",
        "plt.plot(val_loss)\n",
        "plt.title('Loss functio per Iteration')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train','val']);"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbox8rflIaDp"
      },
      "source": [
        "\"\"\"PATH = '/content/drive/My Drive/Colab Notebooks/DL4_v2.pth'\n",
        "\n",
        "model = Transformer(encoder, decoder, per_pad_idx, eng_pad_idx, device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LearningRate,betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "model.train()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJeXQ47TGWD"
      },
      "source": [
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S82rLNifIagb"
      },
      "source": [
        "def translation(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.create_src_padding_mask(src_tensor)\n",
        "       \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "      \n",
        "\n",
        "        trg_padding_mask =  model.create_trg_padding_mask(trg_tensor)\n",
        "        trg_mask =   model.create_trg_mask(trg_tensor)\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(trg_tensor, enc_src, trg_mask, trg_padding_mask )\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm0MIK-kRyb8"
      },
      "source": [
        "example_idx = 65\n",
        "#65, 45 , 154 , 89\n",
        "def view_sentence(example_idx):\n",
        "    src = english_test_text[example_idx]\n",
        "    trg = persian_test_text_0[example_idx]\n",
        "\n",
        "    print('English(source):' ,\"\".join(src[:-1]))\n",
        "    print('persian(target):',\"\".join(trg[:-1]) )\n",
        "    predict = translation(src, english, persian, model, device)\n",
        "    print(\"predict:\" ,\" \".join(predict[:-1]) )"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkYnFriNZ99j",
        "outputId": "a61ef95f-bb67-4a02-dcb9-c002a002dbac"
      },
      "source": [
        "a = [1 , 102,107,215,65 ,89 , 156,182,18,51]\n",
        "for i in a:\n",
        "  view_sentence(i)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English(source): it is more comfortable by train \n",
            "persian(target): با قطار خیلی راحتتر است \n",
            "predict: این کار با قطار بیشتر از طریق قطار های بیشتری انجام می‌شود .\n",
            "\n",
            "\n",
            "English(source): would you like to do something in the evening \n",
            "persian(target): آیا عصر دوست دارید کاری انجام دهید \n",
            "predict: شما دوست دارید در عصر عصر شما را انجام دهید ?\n",
            "\n",
            "\n",
            "English(source): okay . goodbye \n",
            "persian(target): باشه . خداحافظ \n",
            "predict: خداحافظ . خداحافظ .\n",
            "\n",
            "\n",
            "English(source): yes , I would suggest the flight at a quarter past seven \n",
            "persian(target): بله ، من پرواز ساعت هفت و ربع را پیشنهاد میکنم \n",
            "predict: بله , من پیشنهاد میکنم که در هفت روز گذشته در یک سفر پرواز کنم .\n",
            "\n",
            "\n",
            "English(source): I did not understand that \n",
            "persian(target): من آن را نفهمیدم \n",
            "predict: من این را درک نمی‌کنم .\n",
            "\n",
            "\n",
            "English(source): what is the name of our hotel \n",
            "persian(target): نام هتل ما چیست \n",
            "predict: نام ما چیست ?\n",
            "\n",
            "\n",
            "English(source): yes . is everything okay so far then \n",
            "persian(target): بله . پس تا به حال همه چیز مرتب است \n",
            "predict: بله , پس همه چیز ? بله , همه چیز ?\n",
            "\n",
            "\n",
            "English(source): fine . let us meet at ten o'clock in the morning . should we go by train \n",
            "persian(target): خوب است . اجازه دهید ساعت ده صبح ملاقات کنیم . آیا باید با قطار برویم \n",
            "predict: اجازه بدهید ساعت ده صبح همدیگر را ملاقات کنیم ? اجازه بدهید ساعت ده صبح همدیگر را ملاقات کنیم .\n",
            "\n",
            "\n",
            "English(source): no idea . we will see . it does not matter \n",
            "persian(target): نظری ندارم . یکدیگر را میبینیم . مهم نیست \n",
            "predict: هیچ ایده ای نیست که ما هیچ ایده ای نداریم .\n",
            "\n",
            "\n",
            "English(source): fine , would you like to do something in the evening \n",
            "persian(target): خوب ، آیا دوست داری عصر کاری انجام دهی \n",
            "predict: خوب است , شما دوست دارید برای انجام کاری انجام دهید ?\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEqxQQbDSrpF",
        "outputId": "48a9371e-0f5f-4e67-d393-0cbcebd6e41c"
      },
      "source": [
        "\n",
        "a = [1 , 102,107,215,65 ,89 , 156,182,18,51]\n",
        "for i in a:\n",
        "  view_sentence(i)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English(source): it is more comfortable by train \n",
            "persian(target): با قطار خیلی راحتتر است \n",
            "predict: این کار بیشتر از طریق قطار بیشتر است .\n",
            "\n",
            "\n",
            "English(source): would you like to do something in the evening \n",
            "persian(target): آیا عصر دوست دارید کاری انجام دهید \n",
            "predict: آیا شما در عصر عصر شما را دوست دارید ?\n",
            "\n",
            "\n",
            "English(source): okay . goodbye \n",
            "persian(target): باشه . خداحافظ \n",
            "predict: خداحافظ . خداحافظ .\n",
            "\n",
            "\n",
            "English(source): yes , I would suggest the flight at a quarter past seven \n",
            "persian(target): بله ، من پرواز ساعت هفت و ربع را پیشنهاد میکنم \n",
            "predict: بله , من پیشنهاد میکنم که یک چهارم ساعت هفت را پیشنهاد میکنم .\n",
            "\n",
            "\n",
            "English(source): I did not understand that \n",
            "persian(target): من آن را نفهمیدم \n",
            "predict: من آن را <unk> .\n",
            "\n",
            "\n",
            "English(source): what is the name of our hotel \n",
            "persian(target): نام هتل ما چیست \n",
            "predict: نام ما چیست ?\n",
            "\n",
            "\n",
            "English(source): yes . is everything okay so far then \n",
            "persian(target): بله . پس تا به حال همه چیز مرتب است \n",
            "predict: بله , پس همه چیز خوب است ? بله .\n",
            "\n",
            "\n",
            "English(source): fine . let us meet at ten o'clock in the morning . should we go by train \n",
            "persian(target): خوب است . اجازه دهید ساعت ده صبح ملاقات کنیم . آیا باید با قطار برویم \n",
            "predict: اجازه بدهید ساعت ده صبح را ملاقات کنیم ? آیا ما باید همدیگر را ملاقات کنیم .\n",
            "\n",
            "\n",
            "English(source): no idea . we will see . it does not matter \n",
            "persian(target): نظری ندارم . یکدیگر را میبینیم . مهم نیست \n",
            "predict: هیچ ایده ای نیست . هیچ ایده ای در این باره نیست .\n",
            "\n",
            "\n",
            "English(source): fine , would you like to do something in the evening \n",
            "persian(target): خوب ، آیا دوست داری عصر کاری انجام دهی \n",
            "predict: خوب است , آیا شما در عصر عصر وقت دارید ?\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2B9J_iVmYW2"
      },
      "source": [
        "def make_hypotheses(example_idx):\n",
        "    src = english_test_text[example_idx]\n",
        "    trg = persian_test_text_0[example_idx]\n",
        "\n",
        "    predict = translation(src, english, persian, model, device)\n",
        "    return (predict[:-1])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu0S2kswmLd8",
        "outputId": "5718cde8-4e14-4cce-8d4b-eb150f6362b2"
      },
      "source": [
        "#import nltk.tranlate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu \n",
        "from nltk.translate.nist_score import corpus_nist\n",
        "\n",
        "bleu_2 = []\n",
        "bleu_3 = []\n",
        "bleu_4 = []\n",
        "nist = []\n",
        "\n",
        "for i in range(len(persian_test_text_0)):\n",
        "  hypotheses = []\n",
        "  refrences = []\n",
        "\n",
        "  hypotheses.append(make_hypotheses(i))\n",
        "  refrences.append(tokenize_persian(persian_test_text_0[i]))\n",
        "  refrences.append(tokenize_persian(persian_test_text_1[i]))\n",
        "  refrences.append(tokenize_persian(persian_test_text_2[i]))\n",
        "  refrences.append(tokenize_persian(persian_test_text_3[i]))\n",
        "  #print(refrences)\n",
        "  weights = (1./5., 1./5., 1./5., 1./5.)\n",
        "  bleu_4.append(corpus_bleu([refrences],hypotheses, weights)) \n",
        "  weights = (1./5., 1./5., 1./5.)\n",
        "  bleu_3.append(corpus_bleu([refrences],hypotheses, weights))\n",
        "  weights = (1./5., 1./5.)\n",
        "  bleu_2.append(corpus_bleu([refrences],hypotheses, weights)) \n",
        "  if i in [5,8,21 , 39 ,46 ,60 , 64 , 69 ,89 ,99 ,107,179,192,216,219,250]:\n",
        "    continue\n",
        "  try :\n",
        "      nist.append(corpus_nist([refrences],hypotheses)) \n",
        "  except  StopIteration:\n",
        "      nist.append(0)\n",
        "\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EECp8OM1fdNL",
        "outputId": "cf89be67-ffde-400f-ffea-d176bd9283a9"
      },
      "source": [
        "np.mean(bleu_2)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4648135614888572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvMi2TwhS5Rt",
        "outputId": "49c074c8-3993-45d5-c4cd-b8912dc5cfcd"
      },
      "source": [
        "np.mean(bleu_3)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1908536071556049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrQriLh1S5hv",
        "outputId": "38ef79f4-318d-40d7-94c4-ebcb6943890a"
      },
      "source": [
        "np.mean(bleu_4)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06911333936315932"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DEbqGwXtk2t",
        "outputId": "d7576532-e03f-46da-a643-6a3d61fc6ff4"
      },
      "source": [
        "np.mean(nist)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5226754752503875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    }
  ]
}