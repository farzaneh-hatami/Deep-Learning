{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_part3_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IOB4XiizglA",
        "outputId": "69df2319-b651-4cdd-e5ae-6aef8195623f"
      },
      "source": [
        "pip install hazm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\r\u001b[K     |█                               | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 25.1MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 7.9MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 41.2MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n",
            "Building wheels for collected packages: libwapiti, nltk\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154155 sha256=7e497b7c31e75ab49632b0ffa60abfb29a4b208f0205e66906f11756a6c9bc3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394488 sha256=85900a7c6bf02a9f2cca15150e03971c7032ff060e01a7ea07f13c6efd853f42\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built libwapiti nltk\n",
            "Installing collected packages: libwapiti, nltk, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZk20AR5_NtE",
        "outputId": "5f6ba1f9-c149-4f8b-8d0c-d7a8d55cc4ef"
      },
      "source": [
        "! pip install -q pyonmttok"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.3MB 195kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln1NpZEyjcHg"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch \n",
        "import requests\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "from hazm import *\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import pyonmttok\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXfx5UQGtS4",
        "outputId": "cecb11a4-b68c-46f3-de76-18449283654e"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huEQHXpGjjfC",
        "outputId": "6c84894d-e329-4af0-d42f-3c80ed8c56a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMwBHXEs7lML"
      },
      "source": [
        "#!ls \"/content/drive/MyDrive/Colab Notebooks/DL_4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEDg4L5W7lYO"
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all.zip\" -d \"//content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErW9fwiE7ld4"
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/Colab Notebooks/DL_4/Test.zip\" -d \"//content/drive/My Drive/Colab Notebooks/DL_4/Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U491nJcutW0V"
      },
      "source": [
        "english_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all/AFEC-merged.en', encoding='utf8').read().split('\\n')\n",
        "persian_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/AFEC-merged-all/AFEC-merged.fa', encoding='utf8').read().split('\\n')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW8YAVwmuYcb"
      },
      "source": [
        "\"\"\"data = {'English': [line for line in english_text],\n",
        "        'Persian': [line for line in persian_text ]}\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6c4xzkR3EUT"
      },
      "source": [
        "#df = pd.DataFrame(data ,  columns = ['English' , 'Persian'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3keeVT8m6GWF"
      },
      "source": [
        "#train , validation = train_test_split(df , test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmycNtyH6GZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "88d2e89d-d42b-4296-9e3f-5bba4fca158e"
      },
      "source": [
        "\"\"\"train.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/train.json',orient='records' , lines =True)\n",
        "validation.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/validation.json',orient='records' , lines =True)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/train.json',orient='records' , lines =True)\\nvalidation.to_json(r'/content/drive/My Drive/Colab Notebooks/DL_4/validation.json',orient='records' , lines =True)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm6x9pTK-6rT"
      },
      "source": [
        "tokenizer = pyonmttok.Tokenizer(\"aggressive\", joiner_annotate = True , segment_numbers = True)\n",
        "learner_eng = pyonmttok.BPELearner(tokenizer = tokenizer , symbols = 3200)\n",
        "learner_per = pyonmttok.BPELearner(tokenizer = tokenizer , symbols = 3200)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1EKQ7kq-6tt"
      },
      "source": [
        "#english words\n",
        "for i in range(len(english_text)):\n",
        "    learner_eng.ingest(english_text[i])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phfxaNZm-63w"
      },
      "source": [
        "#persian wors\n",
        "for i in range(len(persian_text)):\n",
        "    learner_per.ingest(persian_text[i])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOm-2Gf8_sdO"
      },
      "source": [
        "path_eng = \"/content/drive/My Drive/Colab Notebooks/DL_4/model_english\"\n",
        "tokenizer_eng = learner_eng.learn(path_eng)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFmDsaiB_tV8"
      },
      "source": [
        "path_per = \"/content/drive/My Drive/Colab Notebooks/DL_4/model_persian\"\n",
        "tokenizer_per = learner_per.learn(path_per)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6tkmPPi_x2q",
        "outputId": "178ff90b-3e43-472a-f67e-6cdb2a8d52db"
      },
      "source": [
        "with open(path_eng) as model:\n",
        "    assert model.read() \n",
        "\n",
        "def tokenizer_english(text):\n",
        "  tokens, _ = tokenizer_eng.tokenize(text)\n",
        "  return tokens\n",
        "\n",
        "tokenizer_english(english_text[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['North', 'Waziristan', 'operation', 'kills', '5￭', '0', 'more', 'militants']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bUzSyyy_x5N",
        "outputId": "65676b47-ef6d-4bd6-adf7-746d0aa6dc44"
      },
      "source": [
        "with open(path_per) as model:\n",
        "    assert model.read() \n",
        "    \n",
        "def tokenizer_persian(text):\n",
        "  tokens ,_ = tokenizer_per.tokenize(text)\n",
        "  return tokens\n",
        "tokenizer_persian(persian_text[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مرگ', '5￭', '0', 'ستیزه', 'جوی', 'دیگر', 'در', 'عملیات', 'وزیرستان', 'شمالی']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEehwqdh_x7e"
      },
      "source": [
        "#Defines a datatype together with instructions for converting to Tensor.\n",
        "#sequentila -> if false no tokenize applied.\n",
        "#use_vocab : if false data already is numercal.\n",
        "\n",
        "english = Field(sequential = True , use_vocab = True ,init_token = '<sos>', eos_token = '<eos>',  batch_first = True, tokenize = tokenizer_english , lower = True)\n",
        "persian = Field(sequential = True , use_vocab = True ,init_token = '<sos>', eos_token = '<eos>',  batch_first = True, tokenize = tokenizer_persian , lower = True)\n",
        "\n",
        "            "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKvJjSyX7lqg"
      },
      "source": [
        "fields = {'English' : ('english',english), 'Persian' : ('persian',persian)}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1T6NsRFbbD"
      },
      "source": [
        "#Defines a Dataset of columns stored in CSV, TSV, or JSON format.\n",
        "train_data , validation_data = TabularDataset.splits(\n",
        "    path = '/content/drive/My Drive/Colab Notebooks/DL_4/',\n",
        "    train = 'train.json',\n",
        "    validation = 'validation.json',\n",
        "    format = 'json',\n",
        "    fields = fields\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVoaGYbKP6s"
      },
      "source": [
        "english.build_vocab(train_data , min_freq = 6)\n",
        "persian.build_vocab(train_data , min_freq = 6)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_I2T-m403Zz",
        "outputId": "7ebc9064-2af6-4590-f1cc-5b6ef9177be4"
      },
      "source": [
        "len(persian.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOdSJXfuKP8f"
      },
      "source": [
        "train_iterator , validation_iterator = BucketIterator.splits(\n",
        "    (train_data,validation_data),\n",
        "    batch_size = 64,\n",
        "    device='cuda',\n",
        "    sort = False\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP0LrnLiUe3W"
      },
      "source": [
        "Test **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk9H22FmUeQt"
      },
      "source": [
        "english_test_text = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.en', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_0 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa0', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_1 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa1', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_2 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa2', encoding='utf8').read().split('\\n')\n",
        "persian_test_text_3 = open('/content/drive/My Drive/Colab Notebooks/DL_4/Test/Test/test.fa3', encoding='utf8').read().split('\\n')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaJI9goKLXJR"
      },
      "source": [
        "**Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24onM_7LT2B5"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self ,embed_size , heads):\n",
        "    super(SelfAttention , self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.heads = heads\n",
        "    self.heads_dim = embed_size //heads\n",
        "    #print(self.heads_dim)\n",
        "\n",
        "    assert self.heads_dim*heads == embed_size ,\"Embed size need to be div by heads\"\n",
        "\n",
        "    \"\"\"self.values = nn.Linear(self.heads_dim , self.heads_dim , bias = False)\n",
        "    self.keys = nn.Linear(self.heads_dim , self.heads_dim ,bias = False)\n",
        "    self.queries = nn.Linear(self.heads_dim ,self.heads_dim , bias =False)\"\"\"\n",
        "\n",
        "    self.values = nn.Linear(self.embed_size , self.embed_size , bias = False)\n",
        "    self.keys = nn.Linear(self.embed_size , self.embed_size ,bias = False)\n",
        "    self.queries = nn.Linear(self.embed_size ,self.embed_size , bias =False)\n",
        "    self.fc_out = nn.Linear(heads*self.heads_dim , embed_size) #embed_size = heads*heads_dim\n",
        "\n",
        "\n",
        "  def forward(self , values , keys , queries , mask):\n",
        "    #number of training examples /how many example we are sending at the same time\n",
        "    N = queries.shape[0]\n",
        "    value_len , key_len , query_len = values.shape[1] , keys.shape[1] ,queries.shape[1] #these length coresspond to target and sourcr sentences length.\n",
        "    \n",
        "\n",
        "    values = self.values(values)\n",
        "    #print(\"after values\",values.shape)\n",
        "    keys = self.keys(keys)\n",
        "    #print(\"keys\",keys.shape)\n",
        "    queries = self.queries(queries)\n",
        "    #print(\"queries\" ,queries.shape)\n",
        "\n",
        "    #split embeddig into self.heads pieses\n",
        "    values = values.reshape(N , value_len , self.heads , self.heads_dim) # split embed_size into self.heads and self.heads_dim\n",
        "    #print(\"values\",values.shape)\n",
        "    keys = keys.reshape(N , key_len , self.heads , self.heads_dim)\n",
        "    queries = queries.reshape(N , query_len , self.heads , self.heads_dim)\n",
        "\n",
        "    energy = torch.einsum(\"bqhd,bkhd -> bhqk\" , [queries,keys])\n",
        "    #queiries shape: (N,query_len , heads , heads_dim)\n",
        "    #keys shape : (N , key_len ,heads ,heads_dim)\n",
        "    #energy shape : (N, heads , query_len , key_len) #query = target , key = source\n",
        "    #print(\"energy\",energy.shape)\n",
        "    if mask is not None:\n",
        "      #print(\"####mask\",mask.shape)\n",
        "      #print(\"energy\",energy.shape)\n",
        "      #mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "      #print(\"mask\",mask.shape)\n",
        "      mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "      energy = energy.masked_fill(mask == True , float(\"-1e20\"))#if a element of a mask is zero it means that shut that off\n",
        "      #print(\"energy after mask\",energy.shape)\n",
        "    #key_length = value_length\n",
        "    attention = torch.softmax(energy / (self.embed_size **(1/2)) , dim=2)\n",
        "    #print(\"attention\",attention.shape)\n",
        "    out = torch.einsum(\"bhql,blhd->bqhd\",[attention,values]).reshape(N,query_len,self.heads*self.heads_dim)\n",
        "    #print(\"out\",out.shape)\n",
        "    #attention shape :(batch,heads ,query_len ,key_len)\n",
        "    #values shape :(bach) ,value_len ,heads,head_dim)\n",
        "    #after einsum(batch,query_len,heads,head_dim) then flatten last two dimention\n",
        "\n",
        "    out = self.fc_out(out)\n",
        "    #print(\"selfattention\")\n",
        "    return out"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14D2mgTM1mRA"
      },
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size , embed_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "    def forward(self, tokens):\n",
        "\n",
        "        #print(\":tokenembedding\")\n",
        "        return self.embedding(tokens) * math.sqrt(self.embed_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7aX24RoYvvt"
      },
      "source": [
        "#https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size , maxlen = 500):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        den = torch.exp(- torch.arange(0, embed_size, 2)* math.log(10000) / embed_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, embed_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding ):\n",
        "        #print(\"positional_encoding\")\n",
        "        return self.pos_embedding[:token_embedding.size(0), :]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJbUZYqcesb"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,embed_size,heads,dropout,dim_inner):\n",
        "    super(TransformerBlock,self).__init__()\n",
        "    self.attention = SelfAttention(embed_size,heads)\n",
        "    self.norm1 = nn.LayerNorm(embed_size)\n",
        "    self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embed_size,dim_inner),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_inner,embed_size)\n",
        "    \n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,value , key, query, mask):\n",
        "    attention = self.attention(value,key,query,mask)\n",
        "\n",
        "    x = self.dropout(self.norm1(attention))\n",
        "    forward = self.feed_forward(x)\n",
        "    out = self.dropout(self.norm2(forward))\n",
        "    #print(\"transformerblock\")\n",
        "    return out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqNI6OkxowKC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               src_vocab_size, \n",
        "               embed_size, \n",
        "               num_layers,\n",
        "               heads, \n",
        "               dim_inner,\n",
        "               device,\n",
        "               dropout,\n",
        "               max_length, #positional emedding how long is the sentence length\n",
        "  ):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.device = device\n",
        "    self.word_embedding = nn.Embedding(src_vocab_size , embed_size)\n",
        "    self.position_embedding = PositionalEncoding( embed_size ,max_length)\n",
        "\n",
        "    self.encoder_layers = nn.ModuleList(\n",
        "        [\n",
        "         TransformerBlock(\n",
        "             embed_size,\n",
        "             heads,\n",
        "             dropout = dropout,\n",
        "             dim_inner = dim_inner\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self , x , mask):\n",
        "    N, seq_length = x.shape\n",
        "    word_embedding = self.word_embedding(x)\n",
        "    pos_embedding = self.position_embedding(word_embedding)\n",
        "    out = self.dropout(word_embedding+pos_embedding)\n",
        "\n",
        "    for layer in self.encoder_layers:\n",
        "      out = layer(out , out , out, mask)\n",
        "    #print(\"out\",out.shape)\n",
        "    #print(\"encoder\")\n",
        "    return out"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK46aUd7t7-F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, embed_size, heads, num_layers ,trg_vocab_size,max_length ):\n",
        "    super(Decoder,self).__init__()\n",
        "    \n",
        "    self.embed_size = embed_size\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    #self.device = device\n",
        "    self.decoder_layers = nn.ModuleList(\n",
        "        [\n",
        "         nn.TransformerDecoderLayer(\n",
        "             d_model = embed_size,\n",
        "             nhead = heads,\n",
        "             batch_first = True\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.word_embedding = nn.Embedding(trg_vocab_size , embed_size)\n",
        "    self.position_embedding = PositionalEncoding( embed_size ,max_length)\n",
        "    self.fc_out = nn.Linear(embed_size, trg_vocab_size) \n",
        "\n",
        "  def forward(self , target , encoder_src, target_mask ,padding_mask ):\n",
        "\n",
        "    word_embedding = self.word_embedding(target)\n",
        "    pos_embedding = self.position_embedding(target)\n",
        "    out = self.dropout(word_embedding+pos_embedding)\n",
        "\n",
        "\n",
        "    for layer in self.decoder_layers:\n",
        "      out = layer( out, encoder_src ,tgt_mask  = target_mask ,tgt_key_padding_mask = padding_mask)\n",
        "    #print(\"decoder\")\n",
        "    out = self.fc_out(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mubv1yn7S1oU"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(\n",
        "      self, \n",
        "      encoder, \n",
        "      decoder, \n",
        "      src_pad_idx, \n",
        "      trg_pad_idx, \n",
        "      device\n",
        "  ):\n",
        "      super(Transformer , self).__init__()\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.src_pad_idx = src_pad_idx\n",
        "      self.trg_pad_idx = trg_pad_idx\n",
        "      self.device = device\n",
        "      self.pad_trg_idx = persian.vocab.stoi['<pad>']\n",
        "      self.pad_src_idx = english.vocab.stoi['<pad>']\n",
        "\n",
        "\n",
        "  def create_trg_mask(self ,tgt):\n",
        "      N , l = tgt.shape\n",
        "      mask = (torch.triu(torch.ones((l, l),device=self.device)) == 1).transpose(0, 1)\n",
        "      mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "      return mask.to(self.device)\n",
        "\n",
        "  def create_trg_padding_mask(self , tgt):\n",
        "    N , tgt_seq_len = tgt.shape\n",
        "    tgt_padding_mask = (tgt == self.pad_trg_idx)\n",
        "    return tgt_padding_mask.to(self.device)\n",
        "\n",
        "  def create_src_padding_mask(self , src):\n",
        "      src_seq_len = src.shape[1]\n",
        "      src_padding_mask = (src == self.pad_src_idx)\n",
        "      #src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n",
        "      return src_padding_mask.to(self.device)\n",
        "      \n",
        "\n",
        "  def forward(self, src, trg):\n",
        "\n",
        "      trg_mask =self.create_trg_mask(trg)\n",
        "      trg_mask.shape\n",
        "      trg_padding_mask =self.create_trg_padding_mask(trg)\n",
        "      trg_padding_mask.shape\n",
        "      src_padding_mask =self.create_src_padding_mask(src)\n",
        "      src_padding_mask.shape\n",
        "\n",
        "      enc_src = self.encoder(src, src_padding_mask)\n",
        "      out = self.decoder(trg, enc_src,trg_mask, trg_padding_mask)\n",
        "      #print(\"transformer\")\n",
        "      return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ois8txdT0aLh"
      },
      "source": [
        "src_vocab_size = len(english.vocab)\n",
        "trg_vocab_size = len(persian.vocab)\n",
        "per_pad_idx = persian.vocab.stoi[persian.pad_token]\n",
        "eng_pad_idx = english.vocab.stoi[english.pad_token]\n",
        "embed_size = 256\n",
        "num_layers_enc = 3\n",
        "num_layers_dec = 3\n",
        "heads_enc = 8\n",
        "heads_dec = 8\n",
        "dim_inner = 1024\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dropout = 0.1\n",
        "max_length = 500\n",
        "\n",
        "encoder = Encoder(\n",
        "      src_vocab_size, \n",
        "      embed_size, \n",
        "      num_layers_enc, \n",
        "      heads_enc, \n",
        "      dim_inner,\n",
        "      device,\n",
        "      dropout,\n",
        "      max_length)\n",
        "\n",
        "decoder = Decoder(\n",
        "        embed_size,\n",
        "        heads_dec,\n",
        "        num_layers_dec,\n",
        "        trg_vocab_size,\n",
        "        max_length,\n",
        "        #batch_first = True\n",
        "    )\n",
        "\n",
        "model = Transformer(encoder, decoder, per_pad_idx, eng_pad_idx, device).to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMuSZ7j0CU5q"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuFz7ukN3aH6",
        "outputId": "86a464bb-2f5e-4528-f595-dad1803f35d8"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,645,668 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7dMaWyxNdne"
      },
      "source": [
        "LearningRate = 0.0001"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGeQVXAjwvg"
      },
      "source": [
        "LearningRate = 0.0001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LearningRate,betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = per_pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k6seWAFMfNR"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(validation_iterator):\n",
        "\n",
        "            src = batch.english.to(device)\n",
        "            trg = batch.persian.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            output = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "776bMPR_MfKx"
      },
      "source": [
        "def train(model, train_iterator,validation_iterator, optimizer, criterion, clip):\n",
        "\n",
        "    PATH = '/content/drive/My Drive/Colab Notebooks/DL4_part3_v1.pth'\n",
        "    model.train()\n",
        "    \n",
        "    loss_train = []\n",
        "    loss_val = []\n",
        "\n",
        "    iter_loss = 0\n",
        "    L = len(train_iterator)\n",
        "    flag = False\n",
        "    count_iter = 0\n",
        "\n",
        "    count_iter = 0\n",
        "    for epoch in range(10):\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            count_iter +=1\n",
        "\n",
        "            src = batch.english.to(device)\n",
        "            trg = batch.persian.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(src, trg[:,:-1]) #except last one\n",
        "                    \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "                \n",
        "            output_dim = output.shape[-1] #shape akhar\n",
        "                \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "                    \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "                \n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            iter_loss += loss.item()\n",
        "            #iter = epoch*L+i\n",
        "            if  count_iter%500== 0:\n",
        "  \n",
        "              loss_train.append(iter_loss/500)\n",
        "              temp = evaluate(model,validation_iterator,criterion)\n",
        "              loss_val.append(temp)\n",
        "              print(\"epoch:\",epoch+1,\"iteration:\",count_iter ,\"   train loss\" ,iter_loss/500 , \"   validation loss:\",temp)\n",
        "              iter_loss = 0\n",
        "\n",
        "            \n",
        "            if (count_iter) == 30000 :\n",
        "              flag = True\n",
        "              break\n",
        "            else:\n",
        "              continue\n",
        "        if flag == True:\n",
        "          break;\n",
        "              \n",
        "        torch.save(model.state_dict(), PATH)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH)\n",
        "    return model ,loss_train,loss_val"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgnriQrMMfRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b3da3f-4e2a-41e5-a07b-c3a21c7cd8c8"
      },
      "source": [
        "model , train_loss,val_loss = train(model, train_iterator,validation_iterator, optimizer, criterion, clip=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 iteration: 500    train loss 4.367490549087524    validation loss: 4.04120733024918\n",
            "epoch: 1 iteration: 1000    train loss 3.925621750354767    validation loss: 3.9286969641658747\n",
            "epoch: 1 iteration: 1500    train loss 3.893776526927948    validation loss: 3.907252083983377\n",
            "epoch: 1 iteration: 2000    train loss 3.882280610561371    validation loss: 3.8894461812259995\n",
            "epoch: 1 iteration: 2500    train loss 3.863232158660889    validation loss: 3.869663637375163\n",
            "epoch: 1 iteration: 3000    train loss 3.8458825345039367    validation loss: 3.849952298904134\n",
            "epoch: 1 iteration: 3500    train loss 3.836862003326416    validation loss: 3.8370456700013063\n",
            "epoch: 1 iteration: 4000    train loss 3.8195341148376465    validation loss: 3.832563537971996\n",
            "epoch: 1 iteration: 4500    train loss 3.7999805727005005    validation loss: 3.818167751303343\n",
            "epoch: 1 iteration: 5000    train loss 3.7951116647720338    validation loss: 3.7966913971945506\n",
            "epoch: 1 iteration: 5500    train loss 3.783111986160278    validation loss: 3.7878548760280433\n",
            "epoch: 1 iteration: 6000    train loss 3.7737006969451903    validation loss: 3.7843866464133575\n",
            "epoch: 1 iteration: 6500    train loss 3.762278230667114    validation loss: 3.7687585808406365\n",
            "epoch: 1 iteration: 7000    train loss 3.7509898166656495    validation loss: 3.7522392199418255\n",
            "epoch: 1 iteration: 7500    train loss 3.7274548144340516    validation loss: 3.7455163735095587\n",
            "epoch: 1 iteration: 8000    train loss 3.7252894544601443    validation loss: 3.7348746872393885\n",
            "epoch: 1 iteration: 8500    train loss 3.711406029701233    validation loss: 3.718947097297027\n",
            "epoch: 1 iteration: 9000    train loss 3.7083028202056885    validation loss: 3.711877583120471\n",
            "epoch: 1 iteration: 9500    train loss 3.695255564212799    validation loss: 3.7098032285119884\n",
            "epoch: 2 iteration: 10000    train loss 3.6692095475196838    validation loss: 3.695208774326004\n",
            "epoch: 2 iteration: 10500    train loss 3.6443048181533815    validation loss: 3.678169868371197\n",
            "epoch: 2 iteration: 11000    train loss 3.640041470527649    validation loss: 3.6848101252707366\n",
            "epoch: 2 iteration: 11500    train loss 3.640012759208679    validation loss: 3.6726149106694157\n",
            "epoch: 2 iteration: 12000    train loss 3.6354597239494324    validation loss: 3.656230336483394\n",
            "epoch: 2 iteration: 12500    train loss 3.624420922756195    validation loss: 3.647704162553092\n",
            "epoch: 2 iteration: 13000    train loss 3.6254617762565613    validation loss: 3.645483826922479\n",
            "epoch: 2 iteration: 13500    train loss 3.6092628407478333    validation loss: 3.635529541300836\n",
            "epoch: 2 iteration: 14000    train loss 3.6049622597694397    validation loss: 3.6202603208684474\n",
            "epoch: 2 iteration: 14500    train loss 3.5948178091049194    validation loss: 3.62060952899612\n",
            "epoch: 2 iteration: 15000    train loss 3.5844440217018128    validation loss: 3.6069354032801693\n",
            "epoch: 2 iteration: 15500    train loss 3.5714293904304504    validation loss: 3.6002724607414174\n",
            "epoch: 2 iteration: 16000    train loss 3.5711475319862367    validation loss: 3.5934446878522355\n",
            "epoch: 2 iteration: 16500    train loss 3.566401677131653    validation loss: 3.58420220691467\n",
            "epoch: 2 iteration: 17000    train loss 3.5655102262496947    validation loss: 3.587388318052916\n",
            "epoch: 2 iteration: 17500    train loss 3.5516282052993775    validation loss: 3.5752913568621483\n",
            "epoch: 2 iteration: 18000    train loss 3.5368208932876586    validation loss: 3.5612316107081474\n",
            "epoch: 2 iteration: 18500    train loss 3.533439368724823    validation loss: 3.556209147756345\n",
            "epoch: 2 iteration: 19000    train loss 3.524629229545593    validation loss: 3.552081672721934\n",
            "epoch: 3 iteration: 19500    train loss 3.504177777767181    validation loss: 3.5484885010763865\n",
            "epoch: 3 iteration: 20000    train loss 3.4897319173812864    validation loss: 3.534927596332871\n",
            "epoch: 3 iteration: 20500    train loss 3.4742270340919497    validation loss: 3.5383875831265317\n",
            "epoch: 3 iteration: 21000    train loss 3.477822771072388    validation loss: 3.5240656834896478\n",
            "epoch: 3 iteration: 21500    train loss 3.4730322670936586    validation loss: 3.521283927142063\n",
            "epoch: 3 iteration: 22000    train loss 3.461511689186096    validation loss: 3.508769287572843\n",
            "epoch: 3 iteration: 22500    train loss 3.468043518543243    validation loss: 3.5061726327254394\n",
            "epoch: 3 iteration: 23000    train loss 3.4577883286476134    validation loss: 3.5045358967558244\n",
            "epoch: 3 iteration: 23500    train loss 3.453078348636627    validation loss: 3.495989548602951\n",
            "epoch: 3 iteration: 24000    train loss 3.4471215739250183    validation loss: 3.4848527333446753\n",
            "epoch: 3 iteration: 24500    train loss 3.4495353264808655    validation loss: 3.4819148925977332\n",
            "epoch: 3 iteration: 25000    train loss 3.4473665494918824    validation loss: 3.473860141050036\n",
            "epoch: 3 iteration: 25500    train loss 3.4400128688812255    validation loss: 3.4707074833807545\n",
            "epoch: 3 iteration: 26000    train loss 3.429887442588806    validation loss: 3.46648211078109\n",
            "epoch: 3 iteration: 26500    train loss 3.4254659090042114    validation loss: 3.4576726902311092\n",
            "epoch: 3 iteration: 27000    train loss 3.4249596190452576    validation loss: 3.459082644899315\n",
            "epoch: 3 iteration: 27500    train loss 3.4217506799697874    validation loss: 3.4522685487693714\n",
            "epoch: 3 iteration: 28000    train loss 3.42070060300827    validation loss: 3.440114680183268\n",
            "epoch: 3 iteration: 28500    train loss 3.4086202731132507    validation loss: 3.440018790013322\n",
            "epoch: 4 iteration: 29000    train loss 3.3902962203025817    validation loss: 3.4325903859093922\n",
            "epoch: 4 iteration: 29500    train loss 3.362559289932251    validation loss: 3.4266380024847582\n",
            "epoch: 4 iteration: 30000    train loss 3.36253151512146    validation loss: 3.4227498990353022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ickd0RdtuUbP",
        "outputId": "f6ee140c-796b-4ba4-ae74-af9aac6a5d14"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss )\n",
        "plt.plot(val_loss)\n",
        "plt.title('Loss function per Iteration')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train','val']);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbox8rflIaDp"
      },
      "source": [
        "\"\"\"PATH = '/content/drive/My Drive/Colab Notebooks/DL4_part3_v1.pth'\n",
        "\n",
        "model = Transformer(encoder, decoder, per_pad_idx, eng_pad_idx, device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LearningRate,betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "model.train()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJeXQ47TGWD"
      },
      "source": [
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S82rLNifIagb"
      },
      "source": [
        "def translation(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.create_src_padding_mask(src_tensor)\n",
        "       \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "      \n",
        "\n",
        "        trg_padding_mask =  model.create_trg_padding_mask(trg_tensor)\n",
        "        trg_mask =   model.create_trg_mask(trg_tensor)\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(trg_tensor, enc_src, trg_mask, trg_padding_mask )\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukxen_cQOvgp"
      },
      "source": [
        "example_idx = 65\n",
        "#65, 45 , 154 , 89\n",
        "def view_sentence(example_idx):\n",
        "    src = english_test_text[example_idx]\n",
        "    trg = persian_test_text_0[example_idx]\n",
        "\n",
        "    print('English(source):' ,\"\".join(src[:-1]))\n",
        "    print('persian(target):',\"\".join(trg[:-1]) )\n",
        "    predict = translation(src, english, persian, model, device)\n",
        "    print(\"predict:\" ,\" \".join(predict[:-1]) )"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJTMOTYBO74z",
        "outputId": "d4d23aaa-67ef-4eb9-ab6d-3990cfa10ad0"
      },
      "source": [
        "a = [1 , 102,107,215,65 ,89 , 156,182,18,51]\n",
        "for i in a:\n",
        "  view_sentence(i)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English(source): it is more comfortable by train \n",
            "persian(target): با قطار خیلی راحتتر است \n",
            "predict: این یک مسأله مهم است که این ￭‌￭ ها چه چیزی را می ￭‌￭ بی￭ نید .\n",
            "\n",
            "\n",
            "English(source): would you like to do something in the evening \n",
            "persian(target): آیا عصر دوست دارید کاری انجام دهید \n",
            "predict: آیا شما می ￭‌￭ توانید به این کار را ب￭ دهید ?\n",
            "\n",
            "\n",
            "English(source): okay . goodbye \n",
            "persian(target): باشه . خداحافظ \n",
            "predict: ( خنده ) - ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭- ￭-\n",
            "\n",
            "\n",
            "English(source): yes , I would suggest the flight at a quarter past seven \n",
            "persian(target): بله ، من پرواز ساعت هفت و ربع را پیشنهاد میکنم \n",
            "predict: \" من یک کار￭ مند هستم , یک کار￭ مند جدید برای شما است .\n",
            "\n",
            "\n",
            "English(source): I did not understand that \n",
            "persian(target): من آن را نفهمیدم \n",
            "predict: من فکر می ￭‌￭ کنم که این کار را انجام داده ￭‌￭ ام . من فکر می ￭‌￭ کنم که این کار را انجام داده ￭‌￭ ام .\n",
            "\n",
            "\n",
            "English(source): what is the name of our hotel \n",
            "persian(target): نام هتل ما چیست \n",
            "predict: \" آیا فکر می ￭‌￭ کنم که آیا این کار را انجام می ￭‌￭ دهد ?\n",
            "\n",
            "\n",
            "English(source): yes . is everything okay so far then \n",
            "persian(target): بله . پس تا به حال همه چیز مرتب است \n",
            "predict: خوب است ? بله , چه زمانی ?\n",
            "\n",
            "\n",
            "English(source): fine . let us meet at ten o'clock in the morning . should we go by train \n",
            "persian(target): خوب است . اجازه دهید ساعت ده صبح ملاقات کنیم . آیا باید با قطار برویم \n",
            "predict: ما باید به این کار را ب￭ دهیم . ما باید به شما بگوی￭ ید که در آن کار را انجام دهیم .\n",
            "\n",
            "\n",
            "English(source): no idea . we will see . it does not matter \n",
            "persian(target): نظری ندارم . یکدیگر را میبینیم . مهم نیست \n",
            "predict: این چیزی است که ما نمی ￭‌￭ دان￭ یم .\n",
            "\n",
            "\n",
            "English(source): fine , would you like to do something in the evening \n",
            "persian(target): خوب ، آیا دوست داری عصر کاری انجام دهی \n",
            "predict: آیا شما می ￭‌￭ توانید به این کار را ب￭ دهید ?\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4JFTAsoMfYO"
      },
      "source": [
        "def make_hypotheses(example_idx):\n",
        "    src = english_test_text[example_idx]\n",
        "    trg = persian_test_text_0[example_idx]\n",
        "\n",
        "    predict = translation(src, english, persian, model, device)\n",
        "    return (predict[:-1])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fyvaGclyvXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730fc92f-c4ea-4776-8adc-6989e863db3b"
      },
      "source": [
        "#import nltk.tranlate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu \n",
        "from nltk.translate.nist_score import corpus_nist\n",
        "\n",
        "bleu_2 = []\n",
        "bleu_3 = []\n",
        "bleu_4 = []\n",
        "nist = []\n",
        "\n",
        "for i in range(len(persian_test_text_0)):\n",
        "  hypotheses = []\n",
        "  refrences = []\n",
        "\n",
        "  hypotheses.append(make_hypotheses(i))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_0[i]))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_1[i]))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_2[i]))\n",
        "  refrences.append(tokenizer_persian(persian_test_text_3[i]))\n",
        "  #print(refrences)\n",
        "  weights = (1./5., 1./5., 1./5., 1./5.)\n",
        "  bleu_4.append(corpus_bleu([refrences],hypotheses, weights)) \n",
        "  weights = (1./5., 1./5., 1./5.)\n",
        "  bleu_3.append(corpus_bleu([refrences],hypotheses, weights))\n",
        "  weights = (1./5., 1./5.)\n",
        "  bleu_2.append(corpus_bleu([refrences],hypotheses, weights)) \n",
        "  if i in [5,8,21 , 39 ,46 ,60 , 64 , 69 ,89 ,99 ,107,179,192,216,219,250]:\n",
        "    continue\n",
        "  try :\n",
        "      try :\n",
        "          nist.append(corpus_nist([refrences],hypotheses)) \n",
        "      except  StopIteration:\n",
        "          nist.append(0)\n",
        "  except  ZeroDivisionError:\n",
        "      nist.append(0)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn_YqFhgypHK",
        "outputId": "7372a593-ea6e-4f07-dc5a-3650b1994078"
      },
      "source": [
        "np.mean(bleu_2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1340579063275522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_1lQS0GypJn",
        "outputId": "0720ae9f-1761-4849-ef93-d4a7efe88af4"
      },
      "source": [
        "np.mean(bleu_3)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019618717012098514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_v4RIdUypNy",
        "outputId": "49b13630-6ba2-47ff-8e2c-79bdc71367e1"
      },
      "source": [
        "np.mean(bleu_4)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0028870532303852583"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nSQ-1tkywi5",
        "outputId": "5384a058-8d60-40e6-d82e-c481ac4fc677"
      },
      "source": [
        "np.mean(nist)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6365426166269568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}